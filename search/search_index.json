{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documention for <code>mibipret</code> python package","text":"<p>A Python package for prediction and analysis in Microbiome based Remediation. Developed as part of the MiBiRem toolbox for Bioremediation.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install mibipret from GitHub repository, do:</p> <pre><code>git clone git@github.com:MiBiPreT/mibipret.git\ncd mibipret\npython -m pip mibipret .\n</code></pre>"},{"location":"getting-started/development/","title":"<code>mibipret</code> developer documentation","text":""},{"location":"getting-started/development/#development-install","title":"Development install","text":"<pre><code># Create a virtual environment, e.g. with\npython -m venv env\n\n# activate virtual environment\nsource env/bin/activate\n\n# make sure to have a recent version of pip and setuptools\npython -m pip install --upgrade pip setuptools\n\n# (from the project root directory)\n# install mibipret as an editable package\npython -m pip install --no-cache-dir --editable .\n# install development dependencies\npython -m pip install --no-cache-dir --editable .[dev]\n</code></pre> <p>Afterwards check that the install directory is present in the <code>PATH</code> environment variable.</p>"},{"location":"getting-started/development/#running-the-tests","title":"Running the tests","text":"<p>There are two ways to run tests.</p> <p>The first way requires an activated virtual environment with the development tools installed:</p> <pre><code>pytest -v\n</code></pre> <p>The second is to use <code>tox</code>, which can be installed separately (e.g. with <code>pip install tox</code>), i.e. not necessarily inside the virtual environment you use for installing <code>mibipret</code>, but then builds the necessary virtual environments itself by simply running:</p> <pre><code>tox\n</code></pre> <p>Testing with <code>tox</code> allows for keeping the testing environment separate from your development environment. The development environment will typically accumulate (old) packages during development that interfere with testing; this problem is avoided by testing with <code>tox</code>.</p>"},{"location":"getting-started/development/#test-coverage","title":"Test coverage","text":"<p>In addition to just running the tests to see if they pass, they can be used for coverage statistics, i.e. to determine how much of the package\u2019s code is actually executed during tests. In an activated virtual environment with the development tools installed, inside the package directory, run:</p> <pre><code>coverage run\n</code></pre> <p>This runs tests and stores the result in a <code>.coverage</code> file. To see the results on the command line, run</p> <pre><code>coverage report\n</code></pre> <p><code>coverage</code> can also generate output in HTML and other formats; see <code>coverage help</code> for more information.</p>"},{"location":"getting-started/development/#running-linters-locally","title":"Running linters locally","text":"<p>For linting and sorting imports we will use ruff. Running the linters requires an  activated virtual environment with the development tools installed.</p> <pre><code># linter\nruff check .\n\n# linter with automatic fixing\nruff check . --fix\n</code></pre> <p>To fix readability of your code style you can use yapf.</p> <p>You can enable automatic linting with <code>ruff</code> on commit by enabling the git hook from <code>.githooks/pre-commit</code>, like so:</p> <pre><code>git config --local core.hooksPath .githooks\n</code></pre>"},{"location":"getting-started/development/#testing-docs-locally","title":"Testing docs locally","text":"<p>To build the documentation locally, first make sure <code>mkdocs</code> and its dependencies are installed: <pre><code>python -m pip install .[doc]\n</code></pre></p> <p>Then you can build the documentation and serve it locally with <pre><code>mkdocs serve\n</code></pre></p> <p>This will return a URL (e.g. <code>http://127.0.0.1:8000/mibipret/</code>) where the docs site can be viewed.</p>"},{"location":"getting-started/development/#versioning","title":"Versioning","text":"<p>Bumping the version across all files is done with bump-my-version, e.g.</p> <pre><code>bump-my-version major  # bumps from e.g. 0.3.2 to 1.0.0\nbump-my-version minor  # bumps from e.g. 0.3.2 to 0.4.0\nbump-my-version patch  # bumps from e.g. 0.3.2 to 0.3.3\n</code></pre>"},{"location":"getting-started/development/#making-a-release","title":"Making a release","text":"<p>This section describes how to make a release in 3 parts:</p> <ol> <li>preparation</li> <li>making a release on PyPI</li> <li>making a release on GitHub</li> </ol>"},{"location":"getting-started/development/#13-preparation","title":"(1/3) Preparation","text":"<ol> <li>Verify that the information in CITATION.cff is correct.</li> <li>Make sure the version has been updated.</li> <li>Run the unit tests with <code>pytest -v</code></li> </ol>"},{"location":"getting-started/development/#23-pypi","title":"(2/3) PyPI","text":"<p>In a new terminal:</p> <pre><code># OPTIONAL: prepare a new directory with fresh git clone to ensure the release\n# has the state of origin/main branch\ncd $(mktemp -d mibipret.XXXXXX)\ngit clone git@github.com:MiBiPreT/mibipret .\n\n# make sure to have a recent version of pip and the publishing dependencies\npython -m pip install --upgrade pip\npython -m pip install .[publishing]\n\n# create the source distribution and the wheel\npython -m build\n\n# upload to test pypi instance (requires credentials)\npython -m twine upload --repository testpypi dist/*\n</code></pre> <p>Visit https://test.pypi.org/</p> <p>and verify that your package was uploaded successfully. Keep the terminal open, we\u2019ll need it later.</p> <p>In a new terminal, without an activated virtual environment or an env directory:</p> <pre><code>cd $(mktemp -d mibipret-test.XXXXXX)\n\n# prepare a clean virtual environment and activate it\npython -m venv env\nsource env/bin/activate\n\n# make sure to have a recent version of pip and setuptools\npython -m pip install --upgrade pip\n\n# install from test pypi instance:\npython -m pip -v install --no-cache-dir \\\n--index-url https://test.pypi.org/simple/ \\\n--extra-index-url https://pypi.org/simple mibipret\n</code></pre> <p>Check that the package works as it should when installed from pypitest.</p> <p>Then upload to pypi.org with:</p> <pre><code># Back to the first terminal,\n# FINAL STEP: upload to PyPI (requires credentials)\npython -m twine upload dist/*\n</code></pre>"},{"location":"getting-started/development/#33-github","title":"(3/3) GitHub","text":"<p>Don\u2019t forget to also make a release on GitHub. If your repository uses the GitHub-Zenodo integration this will also trigger Zenodo into making a snapshot of your repository and sticking a DOI on it.</p>"},{"location":"reference/reference/","title":"<code>mibipret</code> API reference","text":"<p>Documentation about mibipret.</p>"},{"location":"reference/reference/#mibipret.analysis","title":"<code>analysis</code>","text":"<p>mibipret module for data analysis.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction","title":"<code>reduction</code>","text":"<p>mibipret module for data analysis reducing sample data.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination","title":"<code>ordination</code>","text":"<p>Routines for performing ordination statistics on sample data.</p> <p>@author: Alraune Zech, Jorrit Bakker</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.cca","title":"<code>cca(data_frame, independent_variables, dependent_variables, n_comp=2, verbose=False)</code>","text":"<p>Function that performs Canonical Correspondence Analysis.</p> <p>Function makes use of skbio.stats.ordination.CCA on the input data and gives the site scores and loadings.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.cca--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : list of strings\n    list with column names data to be the independent variables (=environment)\ndependent_variables : list of strings\n    list with column names data to be the dependen variables (=species)\nn_comp : int, default is 2\n    number of dimensions to return\nverbose : Boolean, The default is False.\n    Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.cca--output","title":"Output","text":"<pre><code>results : Dictionary\n    * method: name of ordination method (str)\n    * loadings_independent: loadings of independent variables (np.ndarray)\n    * loadings_dependent: loadings of dependent variables (np.ndarray)\n    * names_independent: names of independent varialbes (list of str)\n    * names_dependent: names of dependent varialbes (list of str)\n    * scores: scores (np.ndarray)\n    * sample_index: names of samples (list of str)\n</code></pre> Source code in <code>mibipret/analysis/reduction/ordination.py</code> <pre><code>def cca(data_frame,\n        independent_variables,\n        dependent_variables,\n        n_comp = 2,\n        verbose = False,\n        ):\n    \"\"\"Function that performs Canonical Correspondence Analysis.\n\n    Function makes use of skbio.stats.ordination.CCA on the input data and gives\n    the site scores and loadings.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : list of strings\n            list with column names data to be the independent variables (=environment)\n        dependent_variables : list of strings\n            list with column names data to be the dependen variables (=species)\n        n_comp : int, default is 2\n            number of dimensions to return\n        verbose : Boolean, The default is False.\n            Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        results : Dictionary\n            * method: name of ordination method (str)\n            * loadings_independent: loadings of independent variables (np.ndarray)\n            * loadings_dependent: loadings of dependent variables (np.ndarray)\n            * names_independent: names of independent varialbes (list of str)\n            * names_dependent: names of dependent varialbes (list of str)\n            * scores: scores (np.ndarray)\n            * sample_index: names of samples (list of str)\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'cca()' on data\")\n        print('==============================================================')\n\n    results = constrained_ordination(data_frame,\n                           independent_variables,\n                           dependent_variables,\n                           method = 'cca',\n                           n_comp = n_comp,\n                           )\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.check_data_frame","title":"<code>check_data_frame(data_frame)</code>","text":"<p>Checking data on correct format.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.check_data_frame--input","title":"Input","text":"<pre><code>data_frame: pd.DataFrame\n    quantities for data analysis given per sample\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.check_data_frame--output","title":"Output","text":"<pre><code>data: pd.DataFrame\n    copy of given dataframe with index set to sample name\ncols: list\n    List of column names\n</code></pre> Source code in <code>mibipret/analysis/reduction/ordination.py</code> <pre><code>def check_data_frame(data_frame):\n    \"\"\"Checking data on correct format.\n\n    Input\n    -----\n        data_frame: pd.DataFrame\n            quantities for data analysis given per sample\n\n    Output\n    ------\n        data: pd.DataFrame\n            copy of given dataframe with index set to sample name\n        cols: list\n            List of column names\n    \"\"\"\n    if not isinstance(data_frame, pd.DataFrame):\n        raise ValueError(\"Calculation not possible with given data. \\\n                          Data has to be a panda-DataFrame or Series \\\n                          but is given as type {}\".format(type(data_frame)))\n    else:\n        data = data_frame.copy()\n        cols = data.columns.to_list()\n        if name_sample in data.columns:\n            data.set_index(name_sample,inplace = True)\n            cols.remove(name_sample)\n\n    return data, cols\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.constrained_ordination","title":"<code>constrained_ordination(data_frame, independent_variables, dependent_variables, method='cca', n_comp=2)</code>","text":"<p>Function that performs constrained ordination.</p> <p>Function makes use of skbio.stats.ordination on the input data and gives the scores and loadings.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.constrained_ordination--input","title":"Input","text":"<pre><code>data_frame : pd.DataFrame\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : list of strings\n   list with column names data to be the independent variables (=environment)\ndependent_variables : list of strings\n   list with column names data to be the dependen variables (=species)\nmethod : string, default is cca\n    specification of ordination method of choice. Options 'cca' &amp; 'rda'\nn_comp : int, default is 2\n    number of dimensions to return\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.constrained_ordination--output","title":"Output","text":"<pre><code>results : Dictionary\n    * method: name of ordination method (str)\n    * loadings_independent: loadings of independent variables (np.ndarray)\n    * loadings_dependent: loadings of dependent variables (np.ndarray)\n    * names_independent: names of independent varialbes (list of str)\n    * names_dependent: names of dependent varialbes (list of str)\n    * scores: scores (np.ndarray)\n    * sample_index: names of samples (list of str)\n</code></pre> Source code in <code>mibipret/analysis/reduction/ordination.py</code> <pre><code>def constrained_ordination(data_frame,\n                           independent_variables,\n                           dependent_variables,\n                           method = 'cca',\n                           n_comp = 2,\n        ):\n    \"\"\"Function that performs constrained ordination.\n\n    Function makes use of skbio.stats.ordination on the input data and gives\n    the scores and loadings.\n\n    Input\n    -----\n        data_frame : pd.DataFrame\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : list of strings\n           list with column names data to be the independent variables (=environment)\n        dependent_variables : list of strings\n           list with column names data to be the dependen variables (=species)\n        method : string, default is cca\n            specification of ordination method of choice. Options 'cca' &amp; 'rda'\n        n_comp : int, default is 2\n            number of dimensions to return\n\n    Output\n    ------\n        results : Dictionary\n            * method: name of ordination method (str)\n            * loadings_independent: loadings of independent variables (np.ndarray)\n            * loadings_dependent: loadings of dependent variables (np.ndarray)\n            * names_independent: names of independent varialbes (list of str)\n            * names_dependent: names of dependent varialbes (list of str)\n            * scores: scores (np.ndarray)\n            * sample_index: names of samples (list of str)\n    \"\"\"\n    data,cols= check_data_frame(data_frame)\n\n    intersection = extract_variables(cols,\n                          independent_variables,\n                          name_variables = 'independent variables'\n                          )\n    data_independent_variables = data[intersection]\n\n    intersection = extract_variables(cols,\n                          dependent_variables,\n                          name_variables = 'dependent variables'\n                          )\n    data_dependent_variables = data[intersection]\n\n    # Checking if the dimensions of the dataframe allow for CCA\n    if (data_dependent_variables.shape[0] &lt; data_dependent_variables.shape[1]) or \\\n        (data_independent_variables.shape[0] &lt; data_independent_variables.shape[1]):\n        raise ValueError(\"Ordination method {} not possible with more variables than samples.\".format(method))\n\n    # Performing constrained ordination using function from scikit-bio.\n    if method == 'cca':\n        try:\n            sci_ordination = sciord.cca(data_dependent_variables, data_independent_variables, scaling = n_comp)\n        except(TypeError,ValueError):\n            raise TypeError(\"Not all column values are numeric values. Consider standardizing data first.\")\n    elif method == 'rda':\n        try:\n            sci_ordination = sciord.rda(data_dependent_variables, data_independent_variables, scaling = n_comp)\n        except(TypeError,ValueError):\n            raise TypeError(\"Not all column values are numeric values. Consider standardizing data first.\")\n    else:\n        raise ValueError(\"Ordination method {} not a valid option.\".format(method))\n\n    loadings_independent = sci_ordination.biplot_scores.to_numpy()[:,0:n_comp]\n    loadings_dependent = sci_ordination.features.to_numpy()[:,0:n_comp]\n    scores = sci_ordination.samples.to_numpy()[:,0:n_comp]\n\n    if loadings_independent.shape[1]&lt;n_comp:\n        raise ValueError(\"Number of dependent variables too small.\")\n\n    results = {\"method\": method,\n               \"loadings_dependent\": loadings_dependent,\n               \"loadings_independent\": loadings_independent,\n               \"names_independent\" : data_independent_variables.columns.to_list(),\n               \"names_dependent\" : data_dependent_variables.columns.to_list(),\n               \"scores\": scores,\n               \"sample_index\" : list(data.index),\n               }\n\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.extract_variables","title":"<code>extract_variables(columns, variables, name_variables='variables')</code>","text":"<p>Checking overlap of two given list.</p> <p>Function is used for checking if a list of variables is present in the column names of a given dataframe (of quantities for data analysis)</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.extract_variables--input","title":"Input","text":"<pre><code>columns: list of strings\n    given extensive list (usually column names of a pd.DataFrame)\nvariables: list of strings\n    list of names to extract/check overlap with strings in list 'column'\nname_variables: str, default is 'variables'\n    name of type of variables given in list 'variables'\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.extract_variables--output","title":"Output","text":"<pre><code>intersection: list\n    list of strings present in both lists 'columns' and 'variables'\n</code></pre> Source code in <code>mibipret/analysis/reduction/ordination.py</code> <pre><code>def extract_variables(columns,\n                      variables,\n                      name_variables = 'variables'\n                      ):\n    \"\"\"Checking overlap of two given list.\n\n    Function is used for checking if a list of variables is present in\n    the column names of a given dataframe (of quantities for data analysis)\n\n    Input\n    -----\n        columns: list of strings\n            given extensive list (usually column names of a pd.DataFrame)\n        variables: list of strings\n            list of names to extract/check overlap with strings in list 'column'\n        name_variables: str, default is 'variables'\n            name of type of variables given in list 'variables'\n\n    Output\n    ------\n        intersection: list\n            list of strings present in both lists 'columns' and 'variables'\n\n    \"\"\"\n    if isinstance(variables,list):\n        intersection = list(set(columns) &amp; set(variables))\n        remainder = list(set(variables) - set(columns))\n        if len(intersection) == 0:\n            raise ValueError(\"No column names for '{}' identified in columns of dataframe.\".format(name_variables))\n        elif len(intersection) &lt; len(variables):\n            print(\"WARNING: not all column names for '{}' are found in dataframe.\".format(name_variables))\n            print('----------------------------------------------------------------')\n            print(\"Columns used in analysis:\", intersection)\n            print(\"Column names not identified in data:\", remainder)\n            print('________________________________________________________________')\n    else:\n        raise ValueError(\"List of column names for '{}' empty or in wrong format.\".format(name_variables))\n\n    return intersection\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.pca","title":"<code>pca(data_frame, independent_variables=False, dependent_variables=False, n_comp=2, verbose=False)</code>","text":"<p>Function that performs Principal Component Analysis.</p> <p>Makes use of routine sklearn.decomposition.PCA on the input data and gives the site scores and loadings.</p> <p>Principal component analysis (PCA) is a linear dimensionality reduction technique with applications in exploratory data analysis, visualization and data preprocessing. The data is linearly transformed onto a new coordinate system such that the directions (principal components) capturing the largest variation in the data can be easily identified.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.pca--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : Boolean or list of strings; default False\n    list with column names to select from data_frame\n    being characterized as independent variables (= environment)\ndependent_variables : Boolean or list of strings; default is False\n    list with column names to select from data_frame\n    being characterized as dependent variables (= species)\nn_comp : int, default is 2\n    Number of components to report\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.pca--output","title":"Output","text":"<pre><code>results : Dictionary\n    containing the scores and loadings of the PCA,\n    the percentage of the variation explained by the first principal components,\n    the correlation coefficient between the first two PCs,\n    names of columns (same length as loadings)\n    names of indices (same length as scores)\n</code></pre> Source code in <code>mibipret/analysis/reduction/ordination.py</code> <pre><code>def pca(data_frame,\n        independent_variables = False,\n        dependent_variables = False,\n        n_comp = 2,\n        verbose = False,\n        ):\n    \"\"\"Function that performs Principal Component Analysis.\n\n    Makes use of routine sklearn.decomposition.PCA on the input data and gives\n    the site scores and loadings.\n\n    Principal component analysis (PCA) is a linear dimensionality reduction\n    technique with applications in exploratory data analysis, visualization\n    and data preprocessing. The data is linearly transformed onto a new\n    coordinate system such that the directions (principal components) capturing\n    the largest variation in the data can be easily identified.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : Boolean or list of strings; default False\n            list with column names to select from data_frame\n            being characterized as independent variables (= environment)\n        dependent_variables : Boolean or list of strings; default is False\n            list with column names to select from data_frame\n            being characterized as dependent variables (= species)\n        n_comp : int, default is 2\n            Number of components to report\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        results : Dictionary\n            containing the scores and loadings of the PCA,\n            the percentage of the variation explained by the first principal components,\n            the correlation coefficient between the first two PCs,\n            names of columns (same length as loadings)\n            names of indices (same length as scores)\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'pca()' on data\")\n        print('==============================================================')\n\n    data,cols= check_data_frame(data_frame)\n\n    if independent_variables is False and dependent_variables is False:\n        data_pca = data\n        names_independent = cols\n        names_dependent = []\n\n    elif independent_variables is not False and dependent_variables is False:\n        names_independent = extract_variables(cols,\n                              independent_variables,\n                              name_variables = 'independent variables'\n                              )\n        names_dependent = []\n        data_pca = data[names_independent]\n    elif independent_variables is False and dependent_variables is not False:\n        names_dependent = extract_variables(cols,\n                              dependent_variables,\n                              name_variables = 'dependent variables'\n                              )\n        names_independent = []\n        data_pca = data[names_dependent]\n\n    else:\n        names_independent = extract_variables(cols,\n                              independent_variables,\n                              name_variables = 'independent variables'\n                              )\n        names_dependent = extract_variables(cols,\n                              dependent_variables,\n                              name_variables = 'dependent variables'\n                              )\n        data_pca = data[names_independent + names_dependent]\n\n    # Checking if the dimensions of the dataframe allow for PCA\n    if data_pca.shape[0] &lt; data_pca.shape[1]:\n        raise ValueError(\"PCA not possible with more variables than samples.\")\n\n    try:\n        # Using scikit.decomposoition.PCA with an amount of components equal\n        # to the amount of variables, then getting the loadings, scores and explained variance ratio.\n        pca = decomposition.PCA(n_components=len(data_pca.columns))\n        pca.fit(data_pca)\n        loadings = pca.components_.T\n        PCAscores = pca.transform(data_pca)\n        variances = pca.explained_variance_ratio_\n    except(ValueError,TypeError):\n        raise TypeError(\"Not all column values are numeric values (or NaN). Consider standardizing data first.\")\n\n    # Taking the first two PC for plotting\n    if dependent_variables is False:\n        loadings_independent = loadings[:, 0:n_comp]\n        loadings_dependent = np.array([[],[]]).T\n    else:\n        loadings_independent = loadings[:-len(names_dependent), 0:n_comp]\n        loadings_dependent = loadings[-len(names_dependent):, 0:n_comp]\n    scores = PCAscores[:, 0:n_comp]\n    percent_explained = np.around(100*variances/np.sum(variances), decimals=2)\n    coef = np.corrcoef(scores[:,0], scores[:,1])[0,1]\n\n    if verbose:\n        print(\"Information about the success of the PCA:\")\n        print('----------------------------------------------------------------')\n        for i in range(len(percent_explained)):\n            print('Principle component {} explains {}% of the total variance.'.format(i,percent_explained[i]))\n        print('\\nThe correlation coefficient between PC1 and PC2 is {}.'.format(coef))\n        print('----------------------------------------------------------------')\n\n    results = {\"method\": 'pca',\n               \"loadings_dependent\": loadings_dependent,\n               \"loadings_independent\": loadings_independent,\n               \"names_independent\" : names_independent,\n               \"names_dependent\" : names_dependent,\n               \"scores\": scores,\n               \"sample_index\" : list(data_pca.index),\n               \"percent_explained\": percent_explained,\n               \"corr_PC1_PC2\": coef,\n               }\n\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.rda","title":"<code>rda(data_frame, independent_variables, dependent_variables, n_comp=2, verbose=False)</code>","text":"<p>Function that performs Redundancy Analysis.</p> <p>Function makes use of skbio.stats.ordination.RDA on the input data and gives the site scores and loadings.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.rda--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : list of strings\n    list with column names data to be the independent variables (=envirnoment)\ndependent_variables : list of strings\n    list with column names data to be the dependent variables (=species)\nn_comp : int, default is 2\n    number of dimensions to return\nverbose : Boolean, The default is False.\n    Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.ordination.rda--output","title":"Output","text":"<pre><code>results : Dictionary\n    * method: name of ordination method (str)\n    * loadings_independent: loadings of independent variables (np.ndarray)\n    * loadings_dependent: loadings of dependent variables (np.ndarray)\n    * names_independent: names of independent varialbes (list of str)\n    * names_dependent: names of dependent varialbes (list of str)\n    * scores: scores (np.ndarray)\n    * sample_index: names of samples (list of str)\n</code></pre> Source code in <code>mibipret/analysis/reduction/ordination.py</code> <pre><code>def rda(data_frame,\n        independent_variables,\n        dependent_variables,\n        n_comp = 2,\n        verbose = False,\n        ):\n    \"\"\"Function that performs Redundancy Analysis.\n\n    Function makes use of skbio.stats.ordination.RDA on the input data and gives\n    the site scores and loadings.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : list of strings\n            list with column names data to be the independent variables (=envirnoment)\n        dependent_variables : list of strings\n            list with column names data to be the dependent variables (=species)\n        n_comp : int, default is 2\n            number of dimensions to return\n        verbose : Boolean, The default is False.\n            Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        results : Dictionary\n            * method: name of ordination method (str)\n            * loadings_independent: loadings of independent variables (np.ndarray)\n            * loadings_dependent: loadings of dependent variables (np.ndarray)\n            * names_independent: names of independent varialbes (list of str)\n            * names_dependent: names of dependent varialbes (list of str)\n            * scores: scores (np.ndarray)\n            * sample_index: names of samples (list of str)\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'rda()' on data\")\n        print('==============================================================')\n\n    results = constrained_ordination(data_frame,\n                           independent_variables,\n                           dependent_variables,\n                           method = 'rda',\n                           n_comp = n_comp,\n                           )\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression","title":"<code>stable_isotope_regression</code>","text":"<p>Routines for performing linear regression on isotope data.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Keeling_regression","title":"<code>Keeling_regression(concentration, delta_mix=None, relative_abundance=None, validate_indices=True, verbose=False, **kwargs)</code>","text":"<p>Performing a linear regression linked to the Keeling plot.</p> <p>A Keeling fit/plot is an approach to identify the isotopic composition of a contaminating source from measured concentrations and isotopic composition (delta) of a target species in the mix of the source and a pool.</p> <p>It is based on the linear relationship of the given quantities (concentration) and delta-values (or alternatively the relative abundance x) which are measured over time or across a spatial interval according to</p> <pre><code>delta_mix = delta_source + m * 1/c_mix\n</code></pre> <p>where m is the slope relating the isotopic quantities of the pool (which mixes with the sourse) by m = (delta_pool + delta_source)*c_pool.</p> <p>The analysis is based on a linear regression of the inverse concentration data against the delta (or x)-values. The parameter of interest, the delta (or relative_abundance, respectively) of the source quantity is the intercept of linear fit with the y-axis, or in other words, the absolute value of the linear fit function.</p> <p>A plot of the results with data and linear trendline can be generate with the method Keeling_plot() [in the module visualize].</p> <p>Note that the approach is only applicable if     (i)  the isotopic composition of the unknown source is constant     (ii) the concentration and isotopic composition of the target compound         is constant (over time or across space)         (i.e. in absence of contamination from the unknown source)</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Keeling_regression--input","title":"Input","text":"<pre><code>concentration : np.array, pd.dataframe\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta_mix : np.array, pd.dataframe (same length as c_mix), default None\n    relative isotope ratio (delta-value) of target substance\nrelative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n    if not None it replaces delta_mix in the inverse estimation and plotting\n    relative abundance of target substance\nvalidate_indices: boolean, default True\n    flag to run index validation (i.e. removal of nan and infinity values)\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n**kwargs : dict\n    keywordarguments dictionary, e.g. for passing forward keywords to\n    valid_indices()\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Keeling_regression--returns","title":"Returns","text":"<pre><code>results : dict\n    results of fitting, including:\n        * coefficients : array/list of lenght 2, where coefficients[0]\n            is the slope of the linear fit and coefficient[1] is the\n            intercept of linear fit with y-axis, reflecting delta\n            (or relative_abundance, respectively) of the source quantity\n        * delta_C: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n        * delta_H: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n</code></pre> Source code in <code>mibipret/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def Keeling_regression(concentration,\n                       delta_mix = None,\n                       relative_abundance = None,\n                       validate_indices = True,\n                       verbose = False,\n                       **kwargs,\n                       ):\n    \"\"\"Performing a linear regression linked to the Keeling plot.\n\n    A Keeling fit/plot is an approach to identify the isotopic composition of a\n    contaminating source from measured concentrations and isotopic composition\n    (delta) of a target species in the mix of the source and a pool.\n\n    It is based on the linear relationship of the given quantities (concentration)\n    and delta-values (or alternatively the relative abundance x) which are measured\n    over time or across a spatial interval according to\n\n        delta_mix = delta_source + m * 1/c_mix\n\n    where m is the slope relating the isotopic quantities of the pool (which mixes\n    with the sourse) by m = (delta_pool + delta_source)*c_pool.\n\n    The analysis is based on a linear regression of the inverse concentration\n    data against the delta (or x)-values. The parameter of interest, the delta\n    (or relative_abundance, respectively) of the source quantity is the\n    intercept of linear fit with the y-axis, or in other words, the absolute\n    value of the linear fit function.\n\n    A plot of the results with data and linear trendline can be generate with the\n    method Keeling_plot() [in the module visualize].\n\n    Note that the approach is only applicable if\n        (i)  the isotopic composition of the unknown source is constant\n        (ii) the concentration and isotopic composition of the target compound\n            is constant (over time or across space)\n            (i.e. in absence of contamination from the unknown source)\n\n    Input\n    -----\n        concentration : np.array, pd.dataframe\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta_mix : np.array, pd.dataframe (same length as c_mix), default None\n            relative isotope ratio (delta-value) of target substance\n        relative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n            if not None it replaces delta_mix in the inverse estimation and plotting\n            relative abundance of target substance\n        validate_indices: boolean, default True\n            flag to run index validation (i.e. removal of nan and infinity values)\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n        **kwargs : dict\n            keywordarguments dictionary, e.g. for passing forward keywords to\n            valid_indices()\n\n    Returns\n    -------\n        results : dict\n            results of fitting, including:\n                * coefficients : array/list of lenght 2, where coefficients[0]\n                    is the slope of the linear fit and coefficient[1] is the\n                    intercept of linear fit with y-axis, reflecting delta\n                    (or relative_abundance, respectively) of the source quantity\n                * delta_C: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n                * delta_H: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'Keeling_regression()' on data\")\n        print('==============================================================')\n\n    if delta_mix is not None:\n        y = delta_mix\n        text = 'delta'\n    elif relative_abundance is not None:\n        y = relative_abundance\n        text = 'relative abundance'\n    else:\n        raise ValueError(\"One of the quantities 'delta_mix' or 'relative_abundance' must be provided\")\n\n    ### ---------------------------------------------------------------------------\n    ### check length of data arrays and remove non-valid values (NaN, inf &amp; zero)\n\n    if validate_indices:\n        data1, data2 = valid_indices(concentration,\n                                 y,\n                                 remove_nan = True,\n                                 remove_infinity = True,\n                                 remove_zero = True,\n                                 **kwargs,\n                                 )\n    else:\n        data1, data2 = concentration,y\n\n    ### ---------------------------------------------------------------------------\n    ### perform linear regression\n\n    coefficients = np.polyfit(1./data1, data2, 1)\n\n    if verbose:\n        print(\"The {} of the source quantity, being the intercept\".format(text))\n        print(\"of the linear fit, is identified with {:.2f}\".format(coefficients[1]))\n        print('______________________________________________________________')\n\n    results = dict(\n        concentration = data1,\n        delta = data2,\n        coefficients = coefficients,\n        )\n\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Lambda_regression","title":"<code>Lambda_regression(delta_C, delta_H, validate_indices=True, verbose=False, **kwargs)</code>","text":"<p>Performing linear regression to achieve Lambda value.</p> <p>The Lambda values relates the \u03b413C versus \u03b42H signatures of a chemical compound. Relative changes in the ratio can indicate the occurrence of specific enzymatic degradation reactions.</p> <p>The analysis is based on a linear regression of the hydrogen versus carbon isotope signatures. The parameter of interest, the Lambda values is the slope of the the linear trend line.</p> <p>A plot of the results with data and linear trendline can be generate with the method Lambda_plot() [in the module visualize].</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Lambda_regression--input","title":"Input","text":"<pre><code>delta_C : np.array, pd.series\n    relative isotope ratio (delta-value) of carbon of target molecule\ndelta_H : np.array, pd.series (same length as delta_C)\n    relative isotope ratio (delta-value) of hydrogen of target molecule\nvalidate_indices: boolean, default True\n    flag to run index validation (i.e. removal of nan and infinity values)\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n**kwargs : dict\n    keywordarguments dictionary, e.g. for passing forward keywords to\n    valid_indices()\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Lambda_regression--returns","title":"Returns","text":"<pre><code>results : dict\n    results of fitting, including:\n        * coefficients : array/list of lenght 2, where coefficients[0]\n            is the slope of the linear fit, reflecting the lambda values\n            and coefficient[1] is the absolute value of the linear function\n        * delta_C: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n        * delta_H: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n</code></pre> Source code in <code>mibipret/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def Lambda_regression(delta_C,\n                      delta_H,\n                      validate_indices = True,\n                      verbose = False,\n                      **kwargs,\n                      ):\n    \"\"\"Performing linear regression to achieve Lambda value.\n\n    The Lambda values relates the \u03b413C versus \u03b42H signatures of a chemical\n    compound. Relative changes in the ratio can indicate the occurrence of\n    specific enzymatic degradation reactions.\n\n    The analysis is based on a linear regression of the hydrogen versus\n    carbon isotope signatures. The parameter of interest, the Lambda values\n    is the slope of the the linear trend line.\n\n    A plot of the results with data and linear trendline can be generate with the\n    method Lambda_plot() [in the module visualize].\n\n    Input\n    -----\n        delta_C : np.array, pd.series\n            relative isotope ratio (delta-value) of carbon of target molecule\n        delta_H : np.array, pd.series (same length as delta_C)\n            relative isotope ratio (delta-value) of hydrogen of target molecule\n        validate_indices: boolean, default True\n            flag to run index validation (i.e. removal of nan and infinity values)\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n        **kwargs : dict\n            keywordarguments dictionary, e.g. for passing forward keywords to\n            valid_indices()\n\n    Returns\n    -------\n        results : dict\n            results of fitting, including:\n                * coefficients : array/list of lenght 2, where coefficients[0]\n                    is the slope of the linear fit, reflecting the lambda values\n                    and coefficient[1] is the absolute value of the linear function\n                * delta_C: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n                * delta_H: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n    \"\"\"\n    ### ---------------------------------------------------------------------------\n    ### check length of data arrays and remove non-valid values (NaN, inf &amp; zero)\n\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'Lambda_regression()' on data\")\n        print('==============================================================')\n\n    if validate_indices:\n        data1, data2 = valid_indices(delta_C,\n                                     delta_H,\n                                     remove_nan = True,\n                                     remove_infinity = True,\n                                     remove_zero=True,\n                                     )\n    else:\n        data1, data2 = delta_C,delta_H\n\n    ### ---------------------------------------------------------------------------\n    ### perform linear regression\n\n    coefficients = np.polyfit(data1, data2, 1)\n\n    if verbose:\n        print(\"Lambda value, being the slope of the linear fit is \\n identified with {:.2f}\".format(coefficients[0]))\n        print('______________________________________________________________')\n\n    results = dict(\n        delta_C = data1,\n        delta_H = data2,\n        coefficients = coefficients,\n        )\n\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Rayleigh_fractionation","title":"<code>Rayleigh_fractionation(concentration, delta, validate_indices=True, verbose=False, **kwargs)</code>","text":"<p>Performing Rayleigh fractionation analysis.</p> <p>Rayleigh fractionation is a common application to characterize the removal of a substance from a finite pool using stable isotopes. It is based on the change in the isotopic composition of the pool due to different kinetics of the change in lighter and heavier isotopes.</p> <p>We follow the most simple approach assuming that the substance removal follows first-order kinetics, where the rate coefficients for the lighter and heavier isotopes of the substance differ due to kinetic isotope fractionation effects. The isotopic composition of the remaining substance in the pool will change over time, leading to the so-called Rayleigh fractionation.</p> <p>The analysis is based on a linear regression of the log-transformed concentration data against the delta-values. The parameter of interest, the kinetic fractionation factor (epsilon or alpha -1) of the removal process is the slope of the the linear trend line.</p> <p>A plot of the results with data and linear trendline can be generate with the method Rayleigh_fractionation_plot() [in the module visualize].</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Rayleigh_fractionation--input","title":"Input","text":"<pre><code>concentration : np.array, pd.dataframe\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta : np.array, pd.dataframe (same length as concentration)\n    relative isotope ratio (delta-value) of target substance\nvalidate_indices: boolean, default True\n    flag to run index validation (i.e. removal of nan and infinity values)\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n**kwargs : dict\n    keywordarguments dictionary, e.g. for passing forward keywords to\n    valid_indices()\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.Rayleigh_fractionation--returns","title":"Returns","text":"<pre><code>results : dict\n    results of fitting, including:\n        * coefficients : array/list of lenght 2, where coefficients[0]\n            is the slope of the linear fit, reflecting the kinetic\n            fractionation factor (epsilon or alpha -1) of the removal process\n            and coefficient[1] is the absolute value of the linear function\n        * delta_C: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n        * delta_H: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n</code></pre> Source code in <code>mibipret/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def Rayleigh_fractionation(concentration,\n                           delta,\n                           validate_indices = True,\n                           verbose = False,\n                           **kwargs,\n                           ):\n    \"\"\"Performing Rayleigh fractionation analysis.\n\n    Rayleigh fractionation is a common application to characterize the removal\n    of a substance from a finite pool using stable isotopes. It is based on the\n    change in the isotopic composition of the pool due to different kinetics of\n    the change in lighter and heavier isotopes.\n\n    We follow the most simple approach assuming that the substance removal follows\n    first-order kinetics, where the rate coefficients for the lighter and heavier\n    isotopes of the substance differ due to kinetic isotope fractionation effects.\n    The isotopic composition of the remaining substance in the pool will change\n    over time, leading to the so-called Rayleigh fractionation.\n\n    The analysis is based on a linear regression of the log-transformed concentration\n    data against the delta-values. The parameter of interest, the kinetic\n    fractionation factor (epsilon or alpha -1) of the removal process is the slope\n    of the the linear trend line.\n\n    A plot of the results with data and linear trendline can be generate with the\n    method Rayleigh_fractionation_plot() [in the module visualize].\n\n    Input\n    -----\n        concentration : np.array, pd.dataframe\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta : np.array, pd.dataframe (same length as concentration)\n            relative isotope ratio (delta-value) of target substance\n        validate_indices: boolean, default True\n            flag to run index validation (i.e. removal of nan and infinity values)\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n        **kwargs : dict\n            keywordarguments dictionary, e.g. for passing forward keywords to\n            valid_indices()\n\n    Returns\n    -------\n        results : dict\n            results of fitting, including:\n                * coefficients : array/list of lenght 2, where coefficients[0]\n                    is the slope of the linear fit, reflecting the kinetic\n                    fractionation factor (epsilon or alpha -1) of the removal process\n                    and coefficient[1] is the absolute value of the linear function\n                * delta_C: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n                * delta_H: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n    \"\"\"\n    ### ---------------------------------------------------------------------------\n    ### check length of data arrays and remove non-valid values (NaN, inf &amp; zero)\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'Rayleigh_fractionation()' on data\")\n        print('==============================================================')\n\n    if validate_indices:\n        data1, data2 = valid_indices(concentration,\n                                 delta,\n                                 remove_nan = True,\n                                 remove_infinity = True,\n                                 remove_zero = True,\n                                 **kwargs,\n                                 )\n    else:\n        data1, data2 = concentration,delta\n\n    ### ---------------------------------------------------------------------------\n    ### perform linear regression\n    if np.any(data1&lt;=0):\n        raise ValueError(\"Concentration data provided is negative, but has to be positive.\")\n\n    coefficients = np.polyfit(np.log(data1), data2, 1)\n\n    if verbose:\n        print(\"The kinetic fractionation factor ('epsilon' or 'alpha-1') of\")\n        print(\"the removal process, being the slope of the linear fit, is \")\n        print(\"identified with {:.2f}\".format(coefficients[0]))\n        print('______________________________________________________________')\n\n    results = dict(\n        concentration = data1,\n        delta = data2,\n        coefficients = coefficients,\n        )\n\n    return results\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.extract_isotope_data","title":"<code>extract_isotope_data(df, molecule, name_13C='delta_13C', name_2H='delta_2H')</code>","text":"<p>Extracts isotope data from standardised input-dataframe.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.extract_isotope_data--parameters","title":"Parameters","text":"<p>df : pd.dataframe     numeric (observational) data molecule : str     name of contaminant molecule to extract isotope data for name_13C : str, default \u2018delta_13C\u2019 (standard name)     name of C13 isotope to extract data for name_2H : str, default \u2018delta_2H\u2019 (standard name)     name of deuterium isotope to extract data for</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.extract_isotope_data--returns","title":"Returns","text":"<p>C_data : np.array     numeric isotope data H_data : np.array     numeric isotope data</p> Source code in <code>mibipret/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def extract_isotope_data(df,\n                         molecule,\n                         name_13C = 'delta_13C',\n                         name_2H = 'delta_2H',\n                         ):\n    \"\"\"Extracts isotope data from standardised input-dataframe.\n\n    Parameters\n    ----------\n    df : pd.dataframe\n        numeric (observational) data\n    molecule : str\n        name of contaminant molecule to extract isotope data for\n    name_13C : str, default 'delta_13C' (standard name)\n        name of C13 isotope to extract data for\n    name_2H : str, default 'delta_2H' (standard name)\n        name of deuterium isotope to extract data for\n\n    Returns\n    -------\n    C_data : np.array\n        numeric isotope data\n    H_data : np.array\n        numeric isotope data\n\n    \"\"\"\n    molecule_standard = names_contaminants.get(molecule.lower(), False)\n    isotope_13C = names_isotopes.get(name_13C.lower(), False)\n    isotope_2H = names_isotopes.get(name_2H.lower(), False)\n\n    if molecule_standard is False:\n        raise ValueError(\"Contaminant (name) unknown: {}\".format(molecule))\n    if isotope_13C is False:\n        raise ValueError(\"Isotope (name) unknown: {}\".format(name_13C))\n    if isotope_2H is False:\n        raise ValueError(\"Isotope (name) unknown: {}\".format(name_2H))\n\n    name_C = '{}-{}'.format(isotope_13C,molecule_standard)\n    name_H = '{}-{}'.format(isotope_2H,molecule_standard)\n\n    if name_C not in df.columns.to_list():\n        raise ValueError(\"No isotope data available for : {}\".format(name_C))\n    if name_H not in df.columns.to_list():\n        raise ValueError(\"No isotope data available for : {}\".format(name_H))\n\n    C_data = df[name_C].values\n    H_data = df[name_H].values\n\n    return C_data, H_data\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.valid_indices","title":"<code>valid_indices(data1, data2, remove_nan=True, remove_infinity=True, remove_zero=False, **kwargs)</code>","text":"<p>Identifies valid indices in two equaly long arrays and compresses both.</p> <p>Optional numerical to remove from array are: nan, infinity and zero values.</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.valid_indices--parameters","title":"Parameters","text":"<p>data1 : np.array or pd.series     numeric data data2 : np.array or pd.series (same len/shape as data1)     numeric data remove_nan : boolean, default True     flag to remove nan-values remove_infinity : boolean, default True     flag to remove infinity values remove_zero : boolean, default False     flag to remove zero values **kwargs : dict     keywordarguments dictionary</p>"},{"location":"reference/reference/#mibipret.analysis.reduction.stable_isotope_regression.valid_indices--returns","title":"Returns","text":"<p>data1 : np.array or pd.series     numeric data of reduced length where only data at valid indices is in data2 : np.array or pd.series     numeric data of reduced length where only data at valid indices is in</p> Source code in <code>mibipret/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def valid_indices(data1,\n                  data2,\n                  remove_nan = True,\n                  remove_infinity = True,\n                  remove_zero = False,\n                  **kwargs,\n                  ):\n    \"\"\"Identifies valid indices in two equaly long arrays and compresses both.\n\n    Optional numerical to remove from array are: nan, infinity and zero values.\n\n    Parameters\n    ----------\n    data1 : np.array or pd.series\n        numeric data\n    data2 : np.array or pd.series (same len/shape as data1)\n        numeric data\n    remove_nan : boolean, default True\n        flag to remove nan-values\n    remove_infinity : boolean, default True\n        flag to remove infinity values\n    remove_zero : boolean, default False\n        flag to remove zero values\n    **kwargs : dict\n        keywordarguments dictionary\n\n    Returns\n    -------\n    data1 : np.array or pd.series\n        numeric data of reduced length where only data at valid indices is in\n    data2 : np.array or pd.series\n        numeric data of reduced length where only data at valid indices is in\n\n    \"\"\"\n    if data1.shape != data2.shape:\n        raise ValueError(\"Shape of provided data must be identical.\")\n\n    valid_indices = np.full(data1.shape, True, dtype=bool)\n\n    if remove_nan:\n        valid_indices *= ~np.isnan(data1) &amp; ~np.isinf(data1)\n    if remove_infinity:\n        valid_indices *= ~np.isnan(data2) &amp; ~np.isinf(data2)\n    if remove_zero:\n        valid_indices *= (data1 != 0) &amp; (data2 != 0)\n\n    return data1[valid_indices],data2[valid_indices]\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample","title":"<code>sample</code>","text":"<p>mibipret module for data analysis performed on each sample.</p>"},{"location":"reference/reference/#mibipret.analysis.sample.properties","title":"<code>properties</code>","text":"<p>Properties for Natural Attenuation Screening.</p> <p>File containing name specifications of quantities and parameters measured in groundwater samples useful for biodegredation and bioremediation analysis</p> <p>@author: A. Zech</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA","title":"<code>screening_NA</code>","text":"<p>Routines for calculating natural attenuation potential.</p> <p>@author: alraune</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.NA_traffic","title":"<code>NA_traffic(data, inplace=False, verbose=False, **kwargs)</code>","text":"<p>Function evaluating if natural attenuation (NA) is ongoing.</p> <p>Function to calculate electron balance, based on electron availability calculated from concentrations of contaminant and electron acceptors.</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.NA_traffic--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Ratio of electron availability\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.NA_traffic--output","title":"Output","text":"<pre><code>traffic : pd.Series\n    Traffic light (decision) based on ratio of electron availability\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def NA_traffic(\n        data,\n        inplace = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Function evaluating if natural attenuation (NA) is ongoing.\n\n    Function to calculate electron balance, based on electron availability\n    calculated from concentrations of contaminant and electron acceptors.\n\n    Input\n    -----\n        data: pd.DataFrame\n            Ratio of electron availability\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        traffic : pd.Series\n            Traffic light (decision) based on ratio of electron availability\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'NA_traffic()' on data\")\n        print('==============================================================')\n\n    cols = check_data(data)\n\n    if names.name_e_balance in cols:\n        e_balance = data[names.name_e_balance]\n    else:\n        e_balance = electron_balance(data,**kwargs)\n        # raise ValueError(\"Electron balance not given in data.\")\n\n    e_bal = e_balance.values\n    traffic = np.where(e_bal&lt;1,\"red\",\"green\")\n    traffic[np.isnan(e_bal)] = 'y'\n\n    NA_traffic = pd.Series(name =names.name_na_traffic_light,data = traffic,index = e_balance.index)\n\n    if inplace:\n        data[names.name_na_traffic_light] = NA_traffic\n\n    if verbose:\n        print(\"Evaluation if natural attenuation (NA) is ongoing:\")#\" for {}\".format(contaminant_group))\n        print('--------------------------------------------------')\n        print(\"Red light: Reduction is limited at {} out of {} locations\".format(\n            np.sum(traffic == \"red\"),len(e_bal)))\n        print(\"Green light: Reduction is limited at {} out of {} locations\".format(\n            np.sum(traffic == \"green\"),len(e_bal)))\n        print(\"Yellow light: No decision possible at {} out of {} locations\".format(\n            np.sum(np.isnan(e_bal)),len(e_bal)))\n        print('________________________________________________________________')\n\n    return NA_traffic\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.available_NP","title":"<code>available_NP(data, inplace=False, verbose=False, **kwargs)</code>","text":"<p>Function calculating available nutrients.</p> <p>Approximating the amount of hydrocarbons that can be degraded based on the amount of nutrients (nitrogen and phosphate available)</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.available_NP--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    nitrate, nitrite and phosphate concentrations in [mg/l]\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n\nOutput\n------\nNP_avail: pd.Series\n    The amount of nutrients for degrading contaminants\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def available_NP(\n        data,\n        inplace = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Function calculating available nutrients.\n\n    Approximating the amount of hydrocarbons that can be degraded based\n    on the amount of nutrients (nitrogen and phosphate available)\n\n    Input\n    -----\n        data: pd.DataFrame\n            nitrate, nitrite and phosphate concentrations in [mg/l]\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n        Output\n        ------\n        NP_avail: pd.Series\n            The amount of nutrients for degrading contaminants\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'available_NP()' on data\")\n        print('==============================================================')\n\n    cols = check_data(data)\n\n    nutrient_list = [names.name_nitrate, names.name_nitrite, names.name_phosphate]\n    list_nut_miss = []\n\n    for nut in nutrient_list:\n        if nut not in cols:\n            list_nut_miss.append(nut)\n    if len(list_nut_miss)&gt;0:\n        raise ValueError(\"Concentrations of nutrient(s) missing:\", list_nut_miss)\n\n    CNs = (data[names.name_nitrate] + data[names.name_nitrite]) * (39. / 4.5)\n    CPs = data[names.name_phosphate] * (39. / 1.)\n    NP_avail =CNs.combine(CPs, min, 0)\n    NP_avail.name = names.name_NP_avail\n\n    if inplace:\n        data[names.name_NP_avail] = NP_avail\n\n    if verbose:\n        print(\"Total NP available is:\\n{}\".format(NP_avail))\n        print('----------------------')\n\n    return NP_avail\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.check_data","title":"<code>check_data(data)</code>","text":"<p>Checking data on correct format.</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.check_data--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    concentration values of quantities\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.check_data--output","title":"Output","text":"<pre><code>cols: list\nList of column names\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def check_data(data):\n    \"\"\"Checking data on correct format.\n\n    Input\n    -----\n        data: pd.DataFrame\n            concentration values of quantities\n\n    Output\n    ------\n        cols: list\n        List of column names\n    \"\"\"\n    if isinstance(data, pd.DataFrame):\n        cols = data.columns.to_list()\n    elif isinstance(data, pd.Series):\n        cols = [data.name]\n    else:\n        raise ValueError(\"Calculation of not possible with given data. \\\n                          Data has to be a panda-DataFrame or Series \\\n                          but is given as type {}\".format(type(data)))\n\n    return cols\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.electron_balance","title":"<code>electron_balance(data, inplace=False, verbose=False, **kwargs)</code>","text":"<p>Decision if natural attenuation is taking place.</p> <p>Function to calculate electron balance, based on electron availability calculated from concentrations of contaminant and electron acceptors</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.electron_balance--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    tabular data containinng \"total_reductors\" and \"total_oxidators\"\n        -total amount of electrons available for reduction [mmol e-/l]\n        -total amount of electrons needed for oxidation [mmol e-/l]\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.electron_balance--output","title":"Output","text":"<pre><code>e_bal : pd.Series\n    Ratio of electron availability: electrons available for reduction\n    devided by electrons needed for oxidation\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def electron_balance(\n        data,\n        inplace = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Decision if natural attenuation is taking place.\n\n    Function to calculate electron balance, based on electron availability\n    calculated from concentrations of contaminant and electron acceptors\n\n    Input\n    -----\n        data: pd.DataFrame\n            tabular data containinng \"total_reductors\" and \"total_oxidators\"\n                -total amount of electrons available for reduction [mmol e-/l]\n                -total amount of electrons needed for oxidation [mmol e-/l]\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        e_bal : pd.Series\n            Ratio of electron availability: electrons available for reduction\n            devided by electrons needed for oxidation\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'electron_balance()' on data\")\n        print('==============================================================')\n\n    cols = check_data(data)\n\n    if names.name_total_reductors in cols:\n        tot_reduct = data[names.name_total_reductors]\n    else:\n        tot_reduct = reductors(data,**kwargs)\n        # raise ValueError(\"Total amount of oxidators not given in data.\")\n\n    if names.name_total_oxidators in cols:\n        tot_oxi = data[names.name_total_oxidators]\n    else:\n        tot_oxi = oxidators(data,**kwargs)\n        # raise ValueError(\"Total amount of reductors not given in data.\")\n\n    e_bal = tot_reduct.div(tot_oxi, axis=0)\n    e_bal.name = names.name_e_balance\n\n    if inplace:\n        data[names.name_e_balance] = e_bal\n\n    if verbose:\n        print(\"Electron balance e_red/e_cont is:\\n{}\".format(e_bal))\n        print('---------------------------------')\n\n    return e_bal #,decision\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.oxidators","title":"<code>oxidators(data, contaminant_group='BTEXIIN', nutrient=False, inplace=False, verbose=False, **kwargs)</code>","text":"<p>Calculate the amount of electron oxidators [mmol e-/l].</p> <p>Calculate the amount of electron oxidators in [mmol e-/l] based on concentrations of contaminants, stiochiometric ratios of reactions, contaminant properties (e.g. molecular masses in [mg/mmol])</p> <p>alternatively: based on nitrogen and phosphate availability</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.oxidators--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant contentrations in [ug/l], i.e. microgram per liter\n    if nutrient is True, data also needs to contain concentrations\n    of Nitrate, Nitrite and Phosphate\ncontaminant_group: str\n    Short name for group of contaminants to use\n    default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\nnutrient: Boolean\n    flag to include oxidator availability based on nutrient supply\n    calls internally routine \"available_NP()\" with data\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.oxidators--output","title":"Output","text":"<pre><code>tot_oxi: pd.Series\n    Total amount of electrons oxidators in [mmol e-/l]\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def oxidators(\n    data,\n    contaminant_group = \"BTEXIIN\",\n    nutrient = False,\n    inplace = False,\n    verbose = False,\n    **kwargs,\n    ):\n    \"\"\"Calculate the amount of electron oxidators [mmol e-/l].\n\n    Calculate the amount of electron oxidators in [mmol e-/l]\n    based on concentrations of contaminants, stiochiometric ratios of reactions,\n    contaminant properties (e.g. molecular masses in [mg/mmol])\n\n    alternatively: based on nitrogen and phosphate availability\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant contentrations in [ug/l], i.e. microgram per liter\n            if nutrient is True, data also needs to contain concentrations\n            of Nitrate, Nitrite and Phosphate\n        contaminant_group: str\n            Short name for group of contaminants to use\n            default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n        nutrient: Boolean\n            flag to include oxidator availability based on nutrient supply\n            calls internally routine \"available_NP()\" with data\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        tot_oxi: pd.Series\n            Total amount of electrons oxidators in [mmol e-/l]\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'oxidators()' on data\")\n        print('==============================================================')\n\n    tot_oxi = 0.\n    cols = check_data(data)\n\n\n    if nutrient:\n        NP_avail = available_NP(data)\n\n    try:\n        eas = names.contaminants[contaminant_group].copy()\n        if (names.name_o_xylene in cols) and (names.name_pm_xylene in cols): # and (names.name_xylene in cols):\n            eas.remove(names.name_xylene)\n\n        for cont in eas:\n            if cont in cols:\n                # tot_oxi += data[cont]*0.001/properties[cont]['molecular_mass']*\n                    #properties[cont]['factor_stoichiometry']\n                if nutrient:\n                    nut_avail = 1000.*NP_avail*properties[cont]['molecular_mass']/(properties[cont]['cs']*12.)\n                    c_min = nut_avail.combine(data[cont], min, 0) # mass concentration in ug/l\n                else:\n                    c_min = data[cont]\n\n                cm_cont = c_min* 0.001/properties[cont]['molecular_mass'] # molar concentration in mmol/l\n\n                tot_oxi += cm_cont *  properties[cont]['factor_stoichiometry']\n            else:\n                print(\"WARNING: No data on {} given, zero concentration assumed.\".format(cont))\n                print('________________________________________________________________')\n    except KeyError:\n        raise ValueError(\"group of contaminant ('contaminant_group') not defined: '{}'\".format(contaminant_group))\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    # if isinstance(tot_oxi, float):\n    #     print(\"\\nWARNING: No data on contaminant concentrations given.\")\n    #     print('________________________________________________________________')\n    #     tot_oxi = False\n    if isinstance(tot_oxi, pd.Series):\n        tot_oxi.rename(names.name_total_oxidators,inplace = True)\n        if verbose:\n            print(\"Total amount of oxidators per well in [mmol e-/l] is:\\n{}\".format(tot_oxi))\n            print('-----------------------------------------------------')\n    else:\n        raise ValueError(\"No data on oxidators or only zero concentrations given.\")\n\n    if inplace:\n        data[names.name_total_oxidators] = tot_oxi\n\n    return tot_oxi\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.reductors","title":"<code>reductors(data, ea_group='ONS', inplace=False, verbose=False, **kwargs)</code>","text":"<p>Calculate the amount of electron reductors [mmol e-/l].</p> <p>making use of imported molecular mass values for quantities in [mg/mmol]</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.reductors--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    concentration values of electron acceptors in [mg/l]\nea_group: str\n    Short name for group of electron acceptors to use\n    default is 'ONS' (for oxygen, nitrate, and sulfate)\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.reductors--output","title":"Output","text":"<pre><code>tot_reduct: pd.Series\nTotal amount of electrons needed for reduction in [mmol e-/l]\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def reductors(\n    data,\n    ea_group = 'ONS',\n    inplace = False,\n    verbose = False,\n    **kwargs,\n    ):\n    \"\"\"Calculate the amount of electron reductors [mmol e-/l].\n\n    making use of imported molecular mass values for quantities in [mg/mmol]\n\n    Input\n    -----\n        data: pd.DataFrame\n            concentration values of electron acceptors in [mg/l]\n        ea_group: str\n            Short name for group of electron acceptors to use\n            default is 'ONS' (for oxygen, nitrate, and sulfate)\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        tot_reduct: pd.Series\n        Total amount of electrons needed for reduction in [mmol e-/l]\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'reductors()' on data\")\n        print('==============================================================')\n\n    tot_reduct = 0.\n    cols= check_data(data)\n\n    try:\n        for ea in names.electron_acceptors[ea_group]:\n            if ea in cols:\n                tot_reduct += properties[ea]['factor_stoichiometry']* data[ea]/properties[ea]['molecular_mass']\n                #     pd.to_numeric(data[ea]) / properties[ea]['molecular_mass']\n            else:\n                print(\"WARNING: No data on {} given, zero concentration assumed.\".format(ea))\n                print('________________________________________________________________')\n    except KeyError:\n        raise ValueError(\"Group of electron acceptors ('ea_group') not defined: '{}'\".format(ea_group))\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    if isinstance(tot_reduct, pd.Series):\n        tot_reduct.rename(names.name_total_reductors,inplace = True)\n        if verbose:\n            print(\"Total amount of electron reductors per well in [mmol e-/l] is:\\n{}\".format(tot_reduct))\n            print('----------------------------------------------------------------')\n    else:\n        raise ValueError(\"No data on electron acceptors or only zero concentrations given.\")\n    # if isinstance(tot_reduct, float) and tot_reduct &lt;= 0.:\n    #     print(\"\\nWARNING: No data on electron acceptor concentrations given.\")\n    #     tot_reduct = False\n\n    if inplace:\n        data[names.name_total_reductors] = tot_reduct\n\n    return tot_reduct\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.screening_NA","title":"<code>screening_NA(data, ea_group='ONS', contaminant_group='BTEXIIN', nutrient=False, inplace=False, verbose=False, **kwargs)</code>","text":"<p>Calculate the amount of electron reductors [mmol e-/l].</p> <p>making use of imported molecular mass values for quantities in [mg/mmol]</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.screening_NA--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Concentration values of\n        - electron acceptors in [mg/l]\n        - contaminants in [ug/l]\n        - nutrients (Nitrate, Nitrite and Phosphate) if nutrient is True\nea_group: str, default 'ONS'\n    Short name for group of electron acceptors to use\n    'ONS' stands for oxygen, nitrate, sulfate and ironII\ncontaminant_group: str, default 'BTEXIIN'\n    Short name for group of contaminants to use\n    'BTEXIIN' stands for benzene, toluene, ethylbenzene, xylene,\n                           indene, indane and naphthaline\nnutrient: Boolean, default False\n    flag to include oxidator availability based on nutrient supply\n    calls internally routine \"available_NP()\" with data\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean, default False\n    verbose flag\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.screening_NA--output","title":"Output","text":"<pre><code>na_data: pd.DataFrame\n    Tabular data with all quantities of NA screening listed per sample\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def screening_NA(\n    data,\n    ea_group = 'ONS',\n    contaminant_group = \"BTEXIIN\",\n    nutrient = False,\n    inplace = False,\n    verbose = False,\n    **kwargs,\n    ):\n    \"\"\"Calculate the amount of electron reductors [mmol e-/l].\n\n    making use of imported molecular mass values for quantities in [mg/mmol]\n\n    Input\n    -----\n        data: pd.DataFrame\n            Concentration values of\n                - electron acceptors in [mg/l]\n                - contaminants in [ug/l]\n                - nutrients (Nitrate, Nitrite and Phosphate) if nutrient is True\n        ea_group: str, default 'ONS'\n            Short name for group of electron acceptors to use\n            'ONS' stands for oxygen, nitrate, sulfate and ironII\n        contaminant_group: str, default 'BTEXIIN'\n            Short name for group of contaminants to use\n            'BTEXIIN' stands for benzene, toluene, ethylbenzene, xylene,\n                                   indene, indane and naphthaline\n        nutrient: Boolean, default False\n            flag to include oxidator availability based on nutrient supply\n            calls internally routine \"available_NP()\" with data\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean, default False\n            verbose flag\n\n    Output\n    ------\n        na_data: pd.DataFrame\n            Tabular data with all quantities of NA screening listed per sample\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'screening_NA()' on data\")\n        print(\" Runs all checks on data: column names, units and values\")\n        print('==============================================================')\n\n    check_data(data)\n\n    tot_reduct = reductors(data,\n                            ea_group = ea_group,\n                            inplace = inplace,\n                            verbose = verbose)\n    tot_oxi = oxidators(data,\n                        contaminant_group = contaminant_group,\n                        nutrient = nutrient,\n                        inplace = inplace,\n                        verbose = verbose)\n    e_bal = electron_balance(data,\n                             inplace = inplace,\n                             verbose = verbose)\n    na_traffic = NA_traffic(data,\n                            contaminant_group = contaminant_group,\n                            inplace = inplace,\n                            verbose = verbose)\n    tot_cont = total_contaminant_concentration(data,\n                                               contaminant_group = contaminant_group,\n                                               inplace = inplace,\n                                               verbose = verbose)\n    na_data = thresholds_for_intervention(data,\n                                          contaminant_group = contaminant_group,\n                                          inplace = inplace,\n                                          verbose = verbose)\n\n    if inplace is False:\n        for add in [tot_cont,na_traffic,e_bal,tot_oxi,tot_reduct]:\n            na_data.insert(2, add.name, add)\n\n        if nutrient:\n            NP_avail = available_NP(data,verbose = verbose)\n            na_data.insert(4, NP_avail.name, NP_avail)\n\n    return na_data\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.thresholds_for_intervention","title":"<code>thresholds_for_intervention(data, contaminant_group='BTEXIIN', inplace=False, verbose=False, **kwargs)</code>","text":"<p>Function to evalute intervention threshold exceedance.</p> <pre><code>Determines which contaminants exceed concentration thresholds set by\nthe Dutch government for intervention.\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.thresholds_for_intervention--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant contentrations in [ug/l], i.e. microgram per liter\ncontaminant_group: str\n    Short name for group of contaminants to use\n    default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean, default False\n    verbose flag\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.thresholds_for_intervention--output","title":"Output","text":"<pre><code>intervention: pd.DataFrame\nDataFrame of similar format as input data with well specification and\nthree columns on intervention threshold exceedance analysis:\n    - traffic light if well requires intervention\n    - number of contaminants exceeding the intervention value\n    - list of contaminants above the threshold of intervention\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def thresholds_for_intervention(\n        data,\n        contaminant_group = \"BTEXIIN\",\n        inplace = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Function to evalute intervention threshold exceedance.\n\n        Determines which contaminants exceed concentration thresholds set by\n        the Dutch government for intervention.\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant contentrations in [ug/l], i.e. microgram per liter\n        contaminant_group: str\n            Short name for group of contaminants to use\n            default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean, default False\n            verbose flag\n\n    Output\n    ------\n        intervention: pd.DataFrame\n        DataFrame of similar format as input data with well specification and\n        three columns on intervention threshold exceedance analysis:\n            - traffic light if well requires intervention\n            - number of contaminants exceeding the intervention value\n            - list of contaminants above the threshold of intervention\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'thresholds_for_intervention()' on data\")\n        print('==============================================================')\n\n    cols= check_data(data)\n\n    if inplace:\n        na_intervention = data\n    else:\n        na_intervention= pd.DataFrame(data, columns=[names.name_sample,names.name_observation_well])\n    traffic = np.zeros(data.shape[0],dtype=int)\n    intervention = [[] for i in range(data.shape[0])]\n\n    try:\n        eas = names.contaminants[contaminant_group].copy()\n        if (names.name_o_xylene in cols) and (names.name_pm_xylene in cols): # and (names.name_xylene in cols):\n            eas.remove(names.name_xylene)\n        for cont in eas:\n            if cont in cols:\n                th_value = properties[cont]['thresholds_for_intervention_NL']\n                traffic += (data[cont].values &gt; th_value)\n                for i in range(data.shape[0]):\n                    if data[cont].values[i] &gt; th_value:\n                        intervention[i].append(cont)\n            else:\n                print(\"WARNING: No data on {} given, zero concentration assumed.\".format(cont))\n                print('________________________________________________________________')\n\n        traffic_light = np.where(traffic&gt;0,\"red\",\"green\")\n        traffic_light[np.isnan(traffic)] = 'y'\n        na_intervention[names.name_intervention_traffic] = traffic_light\n        na_intervention[names.name_intervention_number] = traffic\n        na_intervention[names.name_intervention_contaminants] = intervention\n\n        if verbose:\n            print(\"Evaluation of contaminant concentrations exceeding intervention values for {}:\".format(\n                contaminant_group))\n            print('------------------------------------------------------------------------------------')\n            print(\"Red light: Intervention values exceeded for {} out of {} locations\".format(\n                np.sum(traffic &gt;0),data.shape[0]))\n            print(\"green light: Concentrations below intervention values at {} out of {} locations\".format(\n                np.sum(traffic == 0),data.shape[0]))\n            print(\"Yellow light: No decision possible at {} out of {} locations\".format(\n                np.sum(np.isnan(traffic)),data.shape[0]))\n            print('________________________________________________________________')\n    except KeyError:\n        raise ValueError(\"Group of contaminant ('contaminant_group') not defined: '{}'\".format(contaminant_group))\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    return na_intervention\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.total_contaminant_concentration","title":"<code>total_contaminant_concentration(data, contaminant_group='BTEXIIN', inplace=False, verbose=False, **kwargs)</code>","text":"<p>Function to calculate total concentration of contaminants.</p>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.total_contaminant_concentration--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant contentrations in [ug/l], i.e. microgram per liter\ncontaminant_group: str\n    Short name for group of contaminants to use\n    default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference/#mibipret.analysis.sample.screening_NA.total_contaminant_concentration--output","title":"Output","text":"<pre><code>tot_conc: pd.Series\n    Total concentration of contaminants in [ug/l]\n</code></pre> Source code in <code>mibipret/analysis/sample/screening_NA.py</code> <pre><code>def total_contaminant_concentration(\n        data,\n        contaminant_group = \"BTEXIIN\",\n        inplace = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Function to calculate total concentration of contaminants.\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant contentrations in [ug/l], i.e. microgram per liter\n        contaminant_group: str\n            Short name for group of contaminants to use\n            default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        tot_conc: pd.Series\n            Total concentration of contaminants in [ug/l]\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'total_contaminant_concentration()' on data\")\n        print('==============================================================')\n\n    tot_conc = 0.\n    cols = check_data(data)\n    try:\n        eas = names.contaminants[contaminant_group].copy()\n        if (names.name_o_xylene in cols) and (names.name_pm_xylene in cols): # and (names.name_xylene in cols):\n            eas.remove(names.name_xylene)\n        for cont in eas:\n            if cont in cols:\n                tot_conc += data[cont] # mass concentration in ug/l\n            else:\n                print(\"WARNING: No data on {} given, zero concentration assumed.\".format(cont))\n                print('________________________________________________________________')\n    except KeyError:\n        raise ValueError(\"Group of contaminant ('contaminant_group') not defined: '{}'\".format(contaminant_group))\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    # if isinstance(tot_conc, float):\n    #     print(\"\\nWARNING: No data on contaminant concentrations given.\")\n    #     print('________________________________________________________________')\n    #     tot_conc = False\n    if isinstance(tot_conc, pd.Series):\n        tot_conc.rename(names.name_total_contaminants,inplace = True)\n        if verbose:\n            print(\"Total concentration of {} in [ug/l] is:\\n{}\".format(contaminant_group,tot_conc))\n            print('--------------------------------------------------')\n    else:\n        raise ValueError(\"No data on contaminants or only zero concentrations given.\")\n\n    if inplace:\n        data[names.name_total_contaminants] = tot_conc\n\n    return tot_conc\n</code></pre>"},{"location":"reference/reference/#mibipret.data","title":"<code>data</code>","text":"<p>mibipret module for data handling.</p>"},{"location":"reference/reference/#mibipret.data.check_data","title":"<code>check_data</code>","text":"<p>Functions for data handling and standardization.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.data.check_data.check_columns","title":"<code>check_columns(data_frame, check_metabolites=False, standardize=False, reduce=False, verbose=True)</code>","text":"<p>Function checking names of columns of data frame.</p> <p>Function that looks at the column names and links it to standard names. Optionally, it renames identified column names to the standard names of the model.</p> <pre><code>data_frame: pd.DataFrame\n    dataframe with the measurements\ncheck_metabolites: Boolean, default False\n    Whether to also check on metabolite names\nstandardize: Boolean, default False\n    Whether to standardize identified column names\nreduce: Boolean, default False\n    Whether to reduce data to known quantities\nverbose: Boolean, default True\n    verbosity flag\n</code></pre> <pre><code>tuple: three list containing names of\n        list with identitied quantities in data (but not standardized names)\n        list with unknown quantities in data (not in list of standardized names)\n        list with standard names of identified quantities\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_columns--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference/#mibipret.data.check_data.check_columns--example","title":"Example:","text":"<p>Todo\u2019s:     - complete list of potential contaminants, environmental factors     - add name check for metabolites?</p> Source code in <code>mibipret/data/check_data.py</code> <pre><code>def check_columns(data_frame,\n                  check_metabolites = False,\n                  standardize = False,\n                  reduce = False,\n                  verbose = True):\n    \"\"\"Function checking names of columns of data frame.\n\n    Function that looks at the column names and links it to standard names.\n    Optionally, it renames identified column names to the standard names of the model.\n\n    Args:\n    -------\n        data_frame: pd.DataFrame\n            dataframe with the measurements\n        check_metabolites: Boolean, default False\n            Whether to also check on metabolite names\n        standardize: Boolean, default False\n            Whether to standardize identified column names\n        reduce: Boolean, default False\n            Whether to reduce data to known quantities\n        verbose: Boolean, default True\n            verbosity flag\n\n    Returns:\n    -------\n        tuple: three list containing names of\n                list with identitied quantities in data (but not standardized names)\n                list with unknown quantities in data (not in list of standardized names)\n                list with standard names of identified quantities\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    Todo's:\n        - complete list of potential contaminants, environmental factors\n        - add name check for metabolites?\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'check_columns()' on data\")\n        print('==============================================================')\n\n    data,cols= check_data_frame(data_frame,\n                                sample_name_to_index = False,\n                                inplace = True)\n\n    results = standard_names(cols,\n                             standardize = False,\n                             reduce = False,\n                             check_metabolites = check_metabolites,\n                             verbose = False,\n                             )\n\n    column_names_standard = results[0]\n    column_names_known = results[1]\n    column_names_unknown = results[2]\n    column_names_transform = results[3]\n\n    if standardize:\n        data.columns = [column_names_transform.get(x, x) for x in data.columns]\n\n    if reduce:\n        data.drop(labels = column_names_unknown,axis = 1,inplace=True)\n\n    if verbose:\n        print(\"{} quantities identified in provided data.\".format(len(column_names_known)))\n        print(\"List of names with standard names:\")\n        print('----------------------------------')\n        for i,name in enumerate(column_names_known):\n            print(name,\" --&gt; \",column_names_standard[i])\n        print('----------------------------------')\n        if standardize:\n            print(\"Identified column names have been standardized\")\n        else:\n            print(\"\\nRenaming can be done by setting keyword 'standardize' to True.\\n\")\n        print('________________________________________________________________')\n        print(\"{} quantities have not been identified in provided data:\".format(len(column_names_unknown)))\n        print('---------------------------------------------------------')\n        for i,name in enumerate(column_names_unknown):\n            print(name)\n        print('---------------------------------------------------------')\n        if reduce:\n            print(\"Not identified quantities have been removed from data frame\")\n        else:\n            print(\"\\nReduction to known quantities can be done by setting keyword 'reduce' to True.\\n\")\n        print('================================================================')\n\n    return (column_names_known,column_names_unknown,column_names_standard)\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_data_frame","title":"<code>check_data_frame(data_frame, sample_name_to_index=False, inplace=False)</code>","text":"<p>Checking data on correct format.</p> <p>Tests if provided data is a pandas data frame and provides column names. Optionally it sets the sample name as index.</p>"},{"location":"reference/reference/#mibipret.data.check_data.check_data_frame--input","title":"Input","text":"<pre><code>data_frame: pd.DataFrame\n    quantities for data analysis given per sample\nsample_name_to_index:  Boolean, default False\n    Whether to set the sample name to the index of the DataFrame\ninplace: Boolean, default False\n    Whether to modify the DataFrame rather than creating a new one.\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_data_frame--output","title":"Output","text":"<pre><code>data: pd.DataFrame\n    copy of given dataframe with index set to sample name\ncols: list\n    List of column names\n</code></pre> Source code in <code>mibipret/data/check_data.py</code> <pre><code>def check_data_frame(data_frame,\n                     sample_name_to_index = False,\n                     inplace = False,\n                     ):\n    \"\"\"Checking data on correct format.\n\n    Tests if provided data is a pandas data frame and provides column names.\n    Optionally it sets the sample name as index.\n\n    Input\n    -----\n        data_frame: pd.DataFrame\n            quantities for data analysis given per sample\n        sample_name_to_index:  Boolean, default False\n            Whether to set the sample name to the index of the DataFrame\n        inplace: Boolean, default False\n            Whether to modify the DataFrame rather than creating a new one.\n\n    Output\n    ------\n        data: pd.DataFrame\n            copy of given dataframe with index set to sample name\n        cols: list\n            List of column names\n    \"\"\"\n    if not isinstance(data_frame, pd.DataFrame):\n        raise ValueError(\"Data has to be a panda-DataFrame or Series \\\n                          but is given as type {}\".format(type(data_frame)))\n\n    if inplace is False:\n        data = data_frame.copy()\n    else:\n        data = data_frame\n\n    if sample_name_to_index:\n        if names.name_sample not in data.columns:\n            print(\"Warning: No sample name provided for making index. Consider standardizing data first\")\n        else:\n            data.set_index(names.name_sample,inplace = True)\n\n    cols = data.columns.to_list()\n\n    return data, cols\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_units","title":"<code>check_units(data, check_metabolites=False, verbose=True)</code>","text":"<p>Function to check the units of the measurements.</p> <pre><code>data: pandas.DataFrames\n    dataframe with the measurements where first row contains\n    the units or a dataframe with only the column names and units\ncheck_metabolites: Boolean, default False\n    flag to check on metabolites' units\nverbose: Boolean\n    verbose statement (default True)\n</code></pre> <pre><code>col_check_list: list\n    quantities whose units need checking/correction\n</code></pre> <pre><code>None (yet).\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_units--example","title":"Example:","text":"<pre><code>To be added.\n</code></pre> Source code in <code>mibipret/data/check_data.py</code> <pre><code>def check_units(data,\n                check_metabolites = False,\n                verbose = True):\n    \"\"\"Function to check the units of the measurements.\n\n    Args:\n    -------\n        data: pandas.DataFrames\n            dataframe with the measurements where first row contains\n            the units or a dataframe with only the column names and units\n        check_metabolites: Boolean, default False\n            flag to check on metabolites' units\n        verbose: Boolean\n            verbose statement (default True)\n\n    Returns:\n    -------\n        col_check_list: list\n            quantities whose units need checking/correction\n\n    Raises:\n    -------\n        None (yet).\n\n    Example:\n    -------\n        To be added.\n    \"\"\"\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'check_units()' on data\")\n        print('================================================================')\n\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Provided data is not a data frame.\")\n    elif data.shape[0]&gt;1:\n        units = data.drop(labels = np.arange(1,data.shape[0]))\n    else:\n        units = data.copy()\n\n    ### testing if provided data frame contains any unit\n    test_unit = False\n    for u in all_units:\n        if u in units.iloc[0].to_list():\n            test_unit = True\n            break\n    if not test_unit:\n        raise ValueError(\"Error: The second line in the dataframe is supposed\\\n                         to specify the units. No units were detected in this\\\n                         line, check www.mibipretdocs.nl/dataloading.\")\n\n    # standardize column names (as it might not has happened for data yet)\n    check_columns(units,standardize = True, check_metabolites=check_metabolites, verbose = False)\n    col_check_list= []\n\n    for quantity in units.columns:\n        if quantity in names.chemical_composition:\n            if units[quantity][0].lower() not in standard_units['mgperl']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be milligramm per liter (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['mgperl'][0]))\n\n        if quantity in names.contaminants['all_cont']:\n            if units[quantity][0].lower() not in standard_units['microgperl']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be microgramm per liter (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['microgperl'][0]))\n\n        if quantity in list(units_env_cond.keys()):\n            unit_type = units_env_cond[quantity]\n            if units[quantity][0].lower() not in standard_units[unit_type]:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be in {} (e.g. {}).\".format(\n                            quantity,units[quantity][0],unit_type,standard_units[unit_type][0]))\n\n        if quantity.split('-')[0] in names.isotopes:\n            if units[quantity][0].lower() not in standard_units['permil']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be per mille (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['permil'][0]))\n\n        if check_metabolites:\n            if quantity in names_meta.metabolites['all_meta']:\n                if units[quantity][0].lower() not in standard_units['microgperl']:\n                    col_check_list.append(quantity)\n                    if verbose:\n                        print(\"Warning: Check unit of {}!\\n Given in {}, but must be microgramm per liter (e.g. {}).\"\n                                  .format(quantity,units[quantity][0],standard_units['microgperl'][0]))\n\n    if verbose:\n        print('________________________________________________________________')\n        if len(col_check_list) == 0:\n            print(\" All identified quantities given in requested units.\")\n        else:\n            print(\" All other identified quantities given in requested units.\")\n        print('================================================================')\n\n    return col_check_list\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_values","title":"<code>check_values(data_frame, inplace=False, verbose=True)</code>","text":"<p>Function that checks on value types and replaces non-measured values.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements (without first row of units)\ninplace: Boolean, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose statement (default True)\n</code></pre> <pre><code>data_pure: pandas.DataFrame\n    Tabular data with standard column names and without units\n</code></pre> <pre><code>None (yet).\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.check_values--example","title":"Example:","text":"<pre><code>To be added.\n</code></pre> Source code in <code>mibipret/data/check_data.py</code> <pre><code>def check_values(data_frame,\n                 inplace = False,\n                 verbose = True,\n                 ):\n    \"\"\"Function that checks on value types and replaces non-measured values.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements (without first row of units)\n        inplace: Boolean, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose statement (default True)\n\n    Returns:\n    -------\n        data_pure: pandas.DataFrame\n            Tabular data with standard column names and without units\n\n    Raises:\n    -------\n        None (yet).\n\n    Example:\n    -------\n        To be added.\n    \"\"\"\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'check_values()' on data\")\n        print('================================================================')\n\n    data,cols= check_data_frame(data_frame, inplace = inplace)\n\n    ### testing if provided data frame contains first row with units\n    for u in data.iloc[0].to_list():\n        if u in all_units:\n            print(\"WARNING: First row identified as units, has been removed for value check\")\n            print('________________________________________________________________')\n            data.drop(labels = 0,inplace = True)\n            break\n\n    for sign in to_replace_list:\n        data.iloc[:,:] = data.iloc[:,:].replace(to_replace=sign, value=to_replace_value)\n\n    # standardize column names (as it might not has happened for data yet)\n    # check_columns(data,\n    #               standardize = True,\n    #               check_metabolites=True,\n    #               verbose = False)\n\n    # transform data to numeric values\n    quantities_transformed = []\n    for quantity in cols: #data.columns:\n        try:\n            # data_pure.loc[:,quantity] = pd.to_numeric(data_pure.loc[:,quantity])\n            data[quantity] = pd.to_numeric(data[quantity])\n            quantities_transformed.append(quantity)\n        except ValueError:\n            print(\"WARNING: Cound not transform '{}' to numerical values\".format(quantity))\n            print('________________________________________________________________')\n    if verbose:\n        print(\"Quantities with values transformed to numerical (int/float):\")\n        print('-----------------------------------------------------------')\n        for name in quantities_transformed:\n            print(name)\n        print('================================================================')\n\n    return data\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.standard_names","title":"<code>standard_names(name_list, check_metabolites=False, standardize=True, reduce=False, verbose=False)</code>","text":"<p>Function transforming list of names to standard names.</p> <p>Function that looks at the names (of e.g. environmental variables, contaminants, metabolites, isotopes, etc) and provides the corresponding standard names.</p> <pre><code>name_list: string or list of strings\n    names of quantities to be transformed to standard\ncheck_metabolites: Boolean, default False\n    Whether to check on metabolite names\nstandardize: Boolean, default False\n    Whether to standardize identified column names\nreduce: Boolean, default False\n    Whether to reduce data to known quantities\nverbose: Boolean, default True\n    verbosity flag\n</code></pre> <pre><code>tuple: three list containing names of\n        list with identitied quantities in data (but not standardized names)\n        list with unknown quantities in data (not in list of standardized names)\n        list with standard names of identified quantities\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.standard_names--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference/#mibipret.data.check_data.standard_names--example","title":"Example:","text":"<p>Todo\u2019s:     - complete list of potential contaminants, environmental factors     - add name check for metabolites?</p> Source code in <code>mibipret/data/check_data.py</code> <pre><code>def standard_names(name_list,\n                   check_metabolites = False,\n                   standardize = True,\n                   reduce = False,\n                   verbose = False,\n                   ):\n    \"\"\"Function transforming list of names to standard names.\n\n    Function that looks at the names (of e.g. environmental variables, contaminants,\n    metabolites, isotopes, etc) and provides the corresponding standard names.\n\n    Args:\n    -------\n        name_list: string or list of strings\n            names of quantities to be transformed to standard\n        check_metabolites: Boolean, default False\n            Whether to check on metabolite names\n        standardize: Boolean, default False\n            Whether to standardize identified column names\n        reduce: Boolean, default False\n            Whether to reduce data to known quantities\n        verbose: Boolean, default True\n            verbosity flag\n\n    Returns:\n    -------\n        tuple: three list containing names of\n                list with identitied quantities in data (but not standardized names)\n                list with unknown quantities in data (not in list of standardized names)\n                list with standard names of identified quantities\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    Todo's:\n        - complete list of potential contaminants, environmental factors\n        - add name check for metabolites?\n    \"\"\"\n    names_standard = []\n    names_known = []\n    names_unknown = []\n    names_transform = {}\n\n    dict_names = names.col_dict.copy()\n\n    if check_metabolites is not False:\n        dict_names.update(names_meta.names_metabolites)\n\n    if isinstance(name_list, str):\n        name_list = [name_list]\n    elif isinstance(name_list, list):\n        for name in name_list:\n            if not isinstance(name, str):\n                raise ValueError(\"Entry in provided list of names is not a string:\", name)\n\n    for x in name_list:\n        y = dict_names.get(x, False)\n        x_isotope = x.split('-')[0]\n        y_isotopes = names.names_isotopes.get(x_isotope.lower(), False)\n\n        if y_isotopes is not False:\n            x_molecule = x.removeprefix(x_isotope+'-')\n            y_molecule = names.names_contaminants.get(x_molecule.lower(), False)\n            if y_molecule is False:\n                names_unknown.append(x)\n            else:\n                y = y_isotopes+'-'+y_molecule\n                names_known.append(x)\n                names_standard.append(y)\n                names_transform[x] = y\n        else:\n            y = dict_names.get(x.lower(), False)\n            if y is False:\n                names_unknown.append(x)\n            else:\n                names_known.append(x)\n                names_standard.append(y)\n                names_transform[x] = y\n\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'standard_names()'\")\n        print('================================================================')\n        print(\"{} of {} quantities identified in name list.\".format(len(names_known),len(name_list)))\n        print(\"List of names with standard names:\")\n        print('----------------------------------')\n        for i,name in enumerate(names_known):\n            print(name,\" --&gt; \",names_standard[i])\n        print('----------------------------------')\n        if standardize:\n            print(\"Identified column names have been standardized\")\n        else:\n            print(\"\\nRenaming can be done by setting keyword 'standardize' to True.\\n\")\n        print('________________________________________________________________')\n        print(\"{} quantities have not been identified in provided data:\".format(len(names_unknown)))\n        print('---------------------------------------------------------')\n        for i,name in enumerate(names_unknown):\n            print(name)\n        print('---------------------------------------------------------')\n        if reduce:\n            print(\"Not identified quantities have been removed from data frame\")\n        else:\n            print(\"\\nReduction to known quantities can be done by setting keyword 'reduce' to True.\\n\")\n        print('================================================================')\n\n    if standardize:\n        if reduce:\n            return names_standard\n        else:\n            return names_standard + names_unknown\n    else:\n        return (names_standard, names_known, names_unknown, names_transform)\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.standardize","title":"<code>standardize(data_frame, check_metabolites=False, reduce=True, store_csv=False, verbose=True)</code>","text":"<p>Function providing condensed data frame with standardized names.</p> <p>Function is checking names of columns and renames columns, condenses data to identified column names, checks units and  names sof data frame.</p> <p>Function that looks at the column names and renames the columns to the standard names of the model.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements\ncheck_metabolites: Boolean, default False\n    whether to check on metabolites' values\nreduce: Boolean, default True\n    whether to reduce data to known quantities (default True),\n    otherwise full dataframe with renamed columns (for those identifyable) is returned\nstore_csv: Boolean, default False\n    whether to save dataframe in standard format to csv-file\nverbose: Boolean, default True\n    verbose statement\n</code></pre> <pre><code>data_numeric, units: pandas.DataFrames\n    Tabular data with standardized column names, values in numerics etc\n    and table with units for standardized column names\n</code></pre> <pre><code>None (yet).\n</code></pre>"},{"location":"reference/reference/#mibipret.data.check_data.standardize--example","title":"Example:","text":"<p>Todo\u2019s:     - complete list of potential contaminants, environmental factors     - add name check for metabolites?     - add key-word to specify which data to extract         (i.e. data columns to return)</p> Source code in <code>mibipret/data/check_data.py</code> <pre><code>def standardize(data_frame,\n                check_metabolites = False,\n                reduce = True,\n                store_csv = False,\n                verbose=True,\n                ):\n    \"\"\"Function providing condensed data frame with standardized names.\n\n    Function is checking names of columns and renames columns,\n    condenses data to identified column names, checks units and  names\n    sof data frame.\n\n    Function that looks at the column names and renames the columns to\n    the standard names of the model.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements\n        check_metabolites: Boolean, default False\n            whether to check on metabolites' values\n        reduce: Boolean, default True\n            whether to reduce data to known quantities (default True),\n            otherwise full dataframe with renamed columns (for those identifyable) is returned\n        store_csv: Boolean, default False\n            whether to save dataframe in standard format to csv-file\n        verbose: Boolean, default True\n            verbose statement\n\n    Returns:\n    -------\n        data_numeric, units: pandas.DataFrames\n            Tabular data with standardized column names, values in numerics etc\n            and table with units for standardized column names\n\n    Raises:\n    -------\n        None (yet).\n\n    Example:\n    -------\n    Todo's:\n        - complete list of potential contaminants, environmental factors\n        - add name check for metabolites?\n        - add key-word to specify which data to extract\n            (i.e. data columns to return)\n\n    \"\"\"\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'standardize()' on data\")\n        print('================================================================')\n        print(' Function performing check of data including:')\n        print('  * check of column names and standardizing them.')\n        print('  * check of units and outlining which to adapt.')\n        print('  * check of values, replacing empty values by nan \\n    and making them numeric')\n\n    data,cols= check_data_frame(data_frame,\n                                sample_name_to_index = False,\n                                inplace = False)\n\n    # general column check &amp; standardize column names\n    check_columns(data,\n                  standardize = True,\n                  reduce = reduce,\n                  check_metabolites = False,\n                  # check_metabolites = check_metabolites,\n                  verbose = verbose)\n\n    # general unit check\n    units = data.drop(labels = np.arange(1,data.shape[0]))\n    col_check_list = check_units(units,\n                                 check_metabolites = check_metabolites,\n                                 verbose = verbose)\n\n    # transform data to numeric values\n    data_numeric = check_values(data.drop(labels = 0),\n                                inplace = False,\n                                verbose = verbose)\n\n    # store standard data to file\n    if store_csv:\n        if len(col_check_list) != 0:\n            print('________________________________________________________________')\n            print(\"Data could not be saved because not all identified \\n quantities are given in requested units.\")\n        else:\n            try:\n                data.to_csv(store_csv,index=False)\n                if verbose:\n                    print('________________________________________________________________')\n                    print(\"Save standardized dataframe to file:\\n\", store_csv)\n            except OSError:\n                print(\"WARNING: data could not be saved. Check provided file path and name: {}\".format(store_csv))\n    if verbose:\n        print('================================================================')\n\n    return data_numeric, units\n</code></pre>"},{"location":"reference/reference/#mibipret.data.example_data","title":"<code>example_data</code>","text":"<p>Example dat.</p> <p>Measurements on quantities and parameters in groundwater samples used for biodegredation and bioremediation analysis.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.data.example_data.example_data","title":"<code>example_data(data_type='all', with_units=False)</code>","text":"<p>Function provinging test data for mibipret data analysis.</p> <pre><code>data_type: string\n    Type of data to return:\n        -- \"all\": all types of data available\n        -- \"set_env_cont\": well setting, environmental and contaminants data\n        -- \"setting\": well setting data only\n        -- \"environment\": data on environmental\n        -- \"contaminants\": data on contaminants\n        -- \"metabolites\": data on metabolites\n        -- \"isotopes\": data on isotopes\n        -- \"hydro\": data on hydrogeolocial conditions\nwith_units: Boolean, default False\n    flag to provide first row with units\n    if False (no units), values in columns will be numerical\n    if True (with units), values in columns will be objects\n</code></pre> <pre><code>pandas.DataFrame: Tabular data with standard column names\n</code></pre> <pre><code>None\n</code></pre>"},{"location":"reference/reference/#mibipret.data.example_data.example_data--example","title":"Example:","text":"<pre><code>To be added!\n</code></pre> Source code in <code>mibipret/data/example_data.py</code> <pre><code>def example_data(data_type = 'all',\n                 with_units = False,\n                 ):\n    \"\"\"Function provinging test data for mibipret data analysis.\n\n    Args:\n    -------\n        data_type: string\n            Type of data to return:\n                -- \"all\": all types of data available\n                -- \"set_env_cont\": well setting, environmental and contaminants data\n                -- \"setting\": well setting data only\n                -- \"environment\": data on environmental\n                -- \"contaminants\": data on contaminants\n                -- \"metabolites\": data on metabolites\n                -- \"isotopes\": data on isotopes\n                -- \"hydro\": data on hydrogeolocial conditions\n        with_units: Boolean, default False\n            flag to provide first row with units\n            if False (no units), values in columns will be numerical\n            if True (with units), values in columns will be objects\n\n    Returns:\n    -------\n        pandas.DataFrame: Tabular data with standard column names\n\n    Raises:\n    -------\n        None\n\n    Example:\n    -------\n        To be added!\n    \"\"\"\n    mgl = standard_units['mgperl'][0]\n    microgl = standard_units['microgperl'][0]\n\n    setting = [names.name_sample,names.name_observation_well,names.name_sample_depth]\n    setting_units = [' ',' ',standard_units['meter'][0]]\n    setting_s01 = ['2000-001', 'B-MLS1-3-12', -12.]\n    setting_s02 = ['2000-002', 'B-MLS1-5-15', -15.5]\n    setting_s03 = ['2000-003', 'B-MLS1-6-17', -17.]\n    setting_s04 = ['2000-004', 'B-MLS1-7-19', -19.]\n\n    environment = [names.name_pH,\n                   names.name_EC,\n                   names.name_redox,\n                   names.name_oxygen,\n                   names.name_nitrate,\n                   names.name_nitrite,\n                   names.name_sulfate,\n                   names.name_ammonium,\n                   names.name_sulfide,\n                   names.name_methane,\n                   names.name_ironII,\n                   names.name_manganese,\n                   names.name_phosphate]\n\n    environment_units = [' ',standard_units['microsimpercm'][0],standard_units['millivolt'][0],\n                         mgl,mgl,mgl,mgl,mgl,mgl,mgl,mgl,mgl,mgl]\n    environment_s01 = [7.23, 322., -208.,0.3,122.,0.58, 23., 5., 0., 748., 3., 1.,1.6]\n    environment_s02 = [7.67, 405., -231.,0.9,5.,0.0, 0., 6., 0., 2022., 1., 0.,0]\n    environment_s03 = [7.75, 223., -252.,0.1,3.,0.03, 1., 13., 0., 200., 1., 0.,0.8]\n    environment_s04 = [7.53, 58., -317.,0., 180.,1., 9., 15., 6., 122., 0., 0.,0.1]\n\n    contaminants = [names.name_benzene,\n                    names.name_toluene,\n                    names.name_ethylbenzene,\n                    names.name_pm_xylene,\n                    names.name_o_xylene,\n                    names.name_indane,\n                    names.name_indene,\n                    names.name_naphthalene]\n\n    contaminants_units = [microgl,microgl,microgl,microgl,\n                          microgl,microgl,microgl,microgl]\n    contaminants_s01 = [263., 2., 269., 14., 51., 1254., 41., 2207.]\n    contaminants_s02 = [179., 7., 1690., 751., 253., 1352., 15., 5410.]\n    contaminants_s03 = [853., 17., 1286., 528., 214., 1031., 31., 3879.]\n    contaminants_s04 = [1254., 10., 1202., 79., 61., 814., 59., 1970.]\n\n    metabolites = [names_meta.name_phenol,\n                   names_meta.name_cinnamic_acid,\n                   names_meta.name_benzoic_acid]\n\n    metabolites_units = [microgl,microgl,microgl]\n    metabolites_s01 = [0.2, 0.4, 1.4]\n    metabolites_s02 = [np.nan, 0.1, 0.]\n    metabolites_s03 = [0., 11.4, 5.4]\n    metabolites_s04 = [0.3, 0.5, 0.7]\n\n    # isotopes = ['delta_13C-benzene','delta_2H-benzene']\n    isotopes = [names.name_13C+'-'+names.name_benzene,\n                names.name_2H+'-'+names.name_benzene,\n                ]\n\n    isotopes_units = [standard_units['permil'][0],standard_units['permil'][0]]\n    isotopes_s01 = [-26.1,-106.]\n    isotopes_s02 = [-25.8,-110.]\n    isotopes_s03 = [-24.1,-118.]\n    isotopes_s04 = [-24.1,-117.]\n\n    if  data_type == 'setting':\n        data = pd.DataFrame([setting_units,setting_s01,setting_s02,setting_s03,\n                             setting_s04],columns = setting)\n\n    elif  data_type == 'environment':\n        units = setting_units+environment_units\n        columns = setting+environment\n        sample_01 = setting_s01+environment_s01\n        sample_02 = setting_s02+environment_s02\n        sample_03 = setting_s03+environment_s03\n        sample_04 = setting_s04+environment_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif  data_type == 'contaminants':\n        units = setting_units+contaminants_units\n        columns = setting+contaminants\n        sample_01 = setting_s01+contaminants_s01\n        sample_02 = setting_s02+contaminants_s02\n        sample_03 = setting_s03+contaminants_s03\n        sample_04 = setting_s04+contaminants_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif  data_type == 'metabolites':\n\n        units = setting_units+metabolites_units\n        columns = setting+metabolites\n        sample_01 = setting_s01+metabolites_s01\n        sample_02 = setting_s02+metabolites_s02\n        sample_03 = setting_s03+metabolites_s03\n        sample_04 = setting_s04+metabolites_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif  data_type == 'isotopes':\n\n        units = setting_units+isotopes_units\n        columns = setting+isotopes\n        sample_01 = setting_s01+isotopes_s01\n        sample_02 = setting_s02+isotopes_s02\n        sample_03 = setting_s03+isotopes_s03\n        sample_04 = setting_s04+isotopes_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif data_type == \"set_env_cont\":\n\n        units = setting_units+environment_units+contaminants_units\n        columns = setting+environment+contaminants\n        sample_01 = setting_s01+environment_s01+contaminants_s01\n        sample_02 = setting_s02+environment_s02+contaminants_s02\n        sample_03 = setting_s03+environment_s03+contaminants_s03\n        sample_04 = setting_s04+environment_s04+contaminants_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif data_type == 'all':\n        units = setting_units+environment_units+contaminants_units+metabolites_units + isotopes_units\n        columns = setting+environment+contaminants+metabolites + isotopes\n        sample_01 = setting_s01+environment_s01+contaminants_s01+metabolites_s01+isotopes_s01\n        sample_02 = setting_s02+environment_s02+contaminants_s02+metabolites_s02+isotopes_s02\n        sample_03 = setting_s03+environment_s03+contaminants_s03+metabolites_s03+isotopes_s03\n        sample_04 = setting_s04+environment_s04+contaminants_s04+metabolites_s04+isotopes_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    else:\n        raise ValueError(\"Specified data type '{}' not available\".format(data_type))\n\n    if not with_units:\n        data.drop(0,inplace = True)\n        for quantity in data.columns[2:]:\n            data[quantity] = pd.to_numeric(data[quantity])\n\n    return data\n</code></pre>"},{"location":"reference/reference/#mibipret.data.load_data","title":"<code>load_data</code>","text":"<p>Functions for data I/O handling.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.data.load_data.load_csv","title":"<code>load_csv(file_path=None, verbose=False, store_provenance=False)</code>","text":"<p>Function to load data from csv file.</p> <pre><code>file_path: str\n    Name of the path to the file\nverbose: Boolean\n    verbose flag\nstore_provenance: Boolean\n    To add!\n</code></pre> <pre><code>data: pd.DataFrame\n    Tabular data\nunits: pd.DataFrame\n    Tabular data on units\n</code></pre> <pre><code>ValueError: If `file_path` is not a valid file location\n</code></pre>"},{"location":"reference/reference/#mibipret.data.load_data.load_csv--example","title":"Example:","text":"<p>This function can be called with the file path of the example data as    argument using:</p> <pre><code>&gt;&gt;&gt; from mibipret.data import load_excel\n&gt;&gt;&gt; load_excel(example_data.csv)\n</code></pre> Source code in <code>mibipret/data/load_data.py</code> <pre><code>def load_csv(\n        file_path = None,\n        verbose = False,\n        store_provenance = False,\n        ):\n    \"\"\"Function to load data from csv file.\n\n    Args:\n    -------\n        file_path: str\n            Name of the path to the file\n        verbose: Boolean\n            verbose flag\n        store_provenance: Boolean\n            To add!\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            Tabular data\n        units: pd.DataFrame\n            Tabular data on units\n\n    Raises:\n    -------\n        ValueError: If `file_path` is not a valid file location\n\n    Example:\n    -------\n       This function can be called with the file path of the example data as\n       argument using:\n\n        &gt;&gt;&gt; from mibipret.data import load_excel\n        &gt;&gt;&gt; load_excel(example_data.csv)\n\n    \"\"\"\n    if file_path is None:\n        raise ValueError('Specify file path and file name!')\n    if not os.path.isfile(file_path):\n        raise OSError('Cannot access file at : ',file_path)\n\n    data = pd.read_csv(file_path, encoding=\"unicode_escape\")\n    if \";\" in data.iloc[1].iloc[0]:\n        data = pd.read_csv(file_path, sep=\";\", encoding=\"unicode_escape\")\n    units = data.drop(labels = np.arange(1,data.shape[0]))\n\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'load_csv()' on data file \", file_path)\n        print('================================================================')\n        print(\"Units of quantities:\")\n        print('-------------------')\n        print(units)\n        print('________________________________________________________________')\n        print(\"Loaded data as pandas DataFrame:\")\n        print('--------------------------------')\n        print(data)\n        print('================================================================')\n\n    return data, units\n</code></pre>"},{"location":"reference/reference/#mibipret.data.load_data.load_excel","title":"<code>load_excel(file_path=None, sheet_name=0, verbose=False, store_provenance=False, **kwargs)</code>","text":"<p>Function to load data from excel file.</p> <pre><code>file_path: str\n    Name of the path to the file\nsheet_name: int\n    Number of the sheet in the excel file to load\nverbose: Boolean\n    verbose flag\nstore_provenance: Boolean\n    To add!\n**kwargs: optional keyword arguments to pass to pandas' routine\n    read_excel()\n</code></pre> <pre><code>data: pd.DataFrame\n    Tabular data\nunits: pd.DataFrame\n    Tabular data on units\n</code></pre> <pre><code>ValueError: If `file_path` is not a valid file location\n</code></pre>"},{"location":"reference/reference/#mibipret.data.load_data.load_excel--example","title":"Example:","text":"<p>This function can be called with the file path of the example data as    argument using:</p> <pre><code>&gt;&gt;&gt; from mibipret.data import load_excel\n&gt;&gt;&gt; load_excel(example_data.xlsx)\n</code></pre> Source code in <code>mibipret/data/load_data.py</code> <pre><code>def load_excel(\n        file_path = None,\n        sheet_name = 0,\n        verbose = False,\n        store_provenance = False,\n        **kwargs,\n        ):\n    \"\"\"Function to load data from excel file.\n\n    Args:\n    -------\n        file_path: str\n            Name of the path to the file\n        sheet_name: int\n            Number of the sheet in the excel file to load\n        verbose: Boolean\n            verbose flag\n        store_provenance: Boolean\n            To add!\n        **kwargs: optional keyword arguments to pass to pandas' routine\n            read_excel()\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            Tabular data\n        units: pd.DataFrame\n            Tabular data on units\n\n    Raises:\n    -------\n        ValueError: If `file_path` is not a valid file location\n\n    Example:\n    -------\n       This function can be called with the file path of the example data as\n       argument using:\n\n        &gt;&gt;&gt; from mibipret.data import load_excel\n        &gt;&gt;&gt; load_excel(example_data.xlsx)\n\n    \"\"\"\n    if file_path is None:\n        raise ValueError('Specify file path and file name!')\n    if not os.path.isfile(file_path):\n        raise OSError('Cannot access file at : ',file_path)\n\n    data = pd.read_excel(file_path,\n                         sheet_name = sheet_name,\n                         **kwargs)\n    if \";\" in data.iloc[1].iloc[0]:\n        data = pd.read_excel(file_path,\n                             sep=\";\",\n                             sheet_name = sheet_name,\n                             **kwargs)\n\n    units = data.drop(labels = np.arange(1,data.shape[0]))\n\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'load_excel()' on data file \", file_path)\n        print('==============================================================')\n        print(\"Unit of quantities:\")\n        print('-------------------')\n        print(units)\n        print('________________________________________________________________')\n        print(\"Loaded data as pandas DataFrame:\")\n        print('--------------------------------')\n        print(data)\n        print('================================================================')\n\n    return data, units\n</code></pre>"},{"location":"reference/reference/#mibipret.data.names_data","title":"<code>names_data</code>","text":"<p>Name specifications of data!</p> <p>File containing name specifications of quantities and parameters measured in groundwater samples useful for biodegredation and bioremediation analysis</p> <p>@author: A. Zech</p>"},{"location":"reference/reference/#mibipret.data.names_metabolites","title":"<code>names_metabolites</code>","text":"<p>Name specifications of metabolite data!</p> <p>File containing name specifications of metabolites measured in groundwater samples useful for biodegredation and bioremediation analysis</p> <p>@author: A. Zech</p>"},{"location":"reference/reference/#mibipret.data.set_data","title":"<code>set_data</code>","text":"<p>Functions for data extraction and merging in preparation of analysis and plotting.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.data.set_data.compare_lists","title":"<code>compare_lists(list1, list2, verbose=False)</code>","text":"<p>Checking overlap of two given list.</p>"},{"location":"reference/reference/#mibipret.data.set_data.compare_lists--input","title":"Input","text":"<pre><code>list1: list of strings\n    given extensive list (usually column names of a pd.DataFrame)\nlist2: list of strings\n    list of names to extract/check overlap with strings in list 'column'\nverbose: Boolean, default True\n    verbosity flag\n</code></pre>"},{"location":"reference/reference/#mibipret.data.set_data.compare_lists--output","title":"Output","text":"<pre><code>(intersection, remainder_list1, reminder_list2): tuple of lists\n    * intersection: list of strings present in both lists 'list1' and 'list2'\n    * remainder_list1: list of strings only present in 'list1'\n    * remainder_list2: list of strings only present in 'list2'\n</code></pre>"},{"location":"reference/reference/#mibipret.data.set_data.compare_lists--example","title":"Example:","text":"<p>list1 = [\u2018test1\u2019,\u2019test2\u2019] list2 =  [\u2018test1\u2019,\u2019test3\u2019]</p> <p>([\u2018test1\u2019],\u2018test2\u2019) = compare_lists(list1,list2)</p> Source code in <code>mibipret/data/set_data.py</code> <pre><code>def compare_lists(list1,\n                  list2,\n                  verbose = False,\n                  ):\n    \"\"\"Checking overlap of two given list.\n\n    Input\n    -----\n        list1: list of strings\n            given extensive list (usually column names of a pd.DataFrame)\n        list2: list of strings\n            list of names to extract/check overlap with strings in list 'column'\n        verbose: Boolean, default True\n            verbosity flag\n\n    Output\n    ------\n        (intersection, remainder_list1, reminder_list2): tuple of lists\n            * intersection: list of strings present in both lists 'list1' and 'list2'\n            * remainder_list1: list of strings only present in 'list1'\n            * remainder_list2: list of strings only present in 'list2'\n\n    Example:\n    -------\n    list1 = ['test1','test2']\n    list2 =  ['test1','test3']\n\n    (['test1'],['test2']['test3']) = compare_lists(list1,list2)\n\n    \"\"\"\n    intersection = list(set(list1) &amp; set(list2))\n    remainder_list1 = list(set(list1) - set(list2))\n    remainder_list2 = list(set(list2) - set(list1))\n\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'extract_variables()'\")\n        print('================================================================')\n        print(\"strings present in both lists:\", intersection)\n        print(\"strings only present in either of the lists:\", remainder_list1 +  remainder_list2)\n\n    return (intersection,remainder_list1,remainder_list2)\n</code></pre>"},{"location":"reference/reference/#mibipret.data.set_data.extract_data","title":"<code>extract_data(data_frame, name_list, keep_setting_data=True)</code>","text":"<p>Extracting data of specified variables from dataframe.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements\nname_list: list of strings\n    list of column names to extract from dataframes\nkeep_setting_data: bool, default True\n    Whether to keep setting data in the DataFrame.\n</code></pre> <pre><code>data: pd.DataFrame\n    dataframe with the measurements\n</code></pre>"},{"location":"reference/reference/#mibipret.data.set_data.extract_data--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference/#mibipret.data.set_data.extract_data--example","title":"Example:","text":"<p>To be added.</p> Source code in <code>mibipret/data/set_data.py</code> <pre><code>def extract_data(data_frame,\n                 name_list,\n                 keep_setting_data = True,\n                 ):\n    \"\"\"Extracting data of specified variables from dataframe.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements\n        name_list: list of strings\n            list of column names to extract from dataframes\n        keep_setting_data: bool, default True\n            Whether to keep setting data in the DataFrame.\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            dataframe with the measurements\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    To be added.\n\n    \"\"\"\n    inter_names,r_columns,r_name_list = compare_lists(data_frame.columns.to_list(),name_list)\n    if len(inter_names)&lt;len(name_list):\n        print(\"Warning: Not all variables in name_list are identified in the data frame columns: \",r_name_list)\n\n    if keep_setting_data:\n        # inter,r1,r2 = compare_lists(data_frame.columns.to_list(),names.setting_data+name_list)\n\n        inter_settings,r1,r2 = compare_lists(data_frame.columns.to_list(),names.setting_data)\n        i1,rim_names,r2 = compare_lists(inter_names,names.setting_data)\n        inter1 = inter_settings + rim_names\n    else:\n        inter1 = inter_names\n\n    data = data_frame[inter1].copy()\n\n    return data\n</code></pre>"},{"location":"reference/reference/#mibipret.data.set_data.merge_data","title":"<code>merge_data(data_frames_list, how='outer', on=[names.name_sample], clean=True, **kwargs)</code>","text":"<p>Merging dataframes along columns on similar sample name.</p> <pre><code>data_frames_list: list of pd.DataFrame\n    list of dataframes with the measurements\nhow: str, default 'outer'\n    Type of merge to be performed.\n    corresponds to keyword in pd.merge()\n    {\u2018left\u2019, \u2018right\u2019, \u2018outer\u2019, \u2018inner\u2019, \u2018cross\u2019}, default \u2018outer\u2019\non: list, default \"sample_nr\"\n    Column name(s) to join on.\n    corresponds to keyword in pd.merge()\nclean: Boolean, default True\n    Whether to drop columns which are in all provided data_frames\n    (on which not to merge, potentially other settings than sample_name)\n**kwargs: dict\n    optional keyword arguments to be passed to pd.merge()\n</code></pre> <pre><code>data: pd.DataFrame\n    dataframe with the measurements\n</code></pre>"},{"location":"reference/reference/#mibipret.data.set_data.merge_data--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference/#mibipret.data.set_data.merge_data--example","title":"Example:","text":"<p>To be added.</p> Source code in <code>mibipret/data/set_data.py</code> <pre><code>def merge_data(data_frames_list,\n               how='outer',\n               on=[names.name_sample],\n               clean = True,\n               **kwargs,\n               ):\n    \"\"\"Merging dataframes along columns on similar sample name.\n\n    Args:\n    -------\n        data_frames_list: list of pd.DataFrame\n            list of dataframes with the measurements\n        how: str, default 'outer'\n            Type of merge to be performed.\n            corresponds to keyword in pd.merge()\n            {\u2018left\u2019, \u2018right\u2019, \u2018outer\u2019, \u2018inner\u2019, \u2018cross\u2019}, default \u2018outer\u2019\n        on: list, default \"sample_nr\"\n            Column name(s) to join on.\n            corresponds to keyword in pd.merge()\n        clean: Boolean, default True\n            Whether to drop columns which are in all provided data_frames\n            (on which not to merge, potentially other settings than sample_name)\n        **kwargs: dict\n            optional keyword arguments to be passed to pd.merge()\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            dataframe with the measurements\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    To be added.\n\n    \"\"\"\n    if len(data_frames_list)&lt;2:\n        raise ValueError('Provide List of DataFrames.')\n\n    data_merge = data_frames_list[0]\n    for data_add in data_frames_list[1:]:\n        if clean:\n            intersection,remainder_list1,remainder_list2 = compare_lists(\n                data_merge.columns.to_list(),data_add.columns.to_list())\n            intersection,remainder_list1,remainder_list2 = compare_lists(intersection,on)\n            data_add = data_add.drop(labels = remainder_list1+remainder_list2,axis = 1)\n        data_merge = pd.merge(data_merge,data_add, how=how, on=on,**kwargs)\n        # complete data set, where values of porosity are added (otherwise nan)\n\n    return data_merge\n</code></pre>"},{"location":"reference/reference/#mibipret.data.unit_settings","title":"<code>unit_settings</code>","text":"<p>Unit specifications of data!</p> <p>File containing unit specifications of quantities and parameters measured in groundwater samples useful for biodegredation and bioremediation analysis.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.visualize","title":"<code>visualize</code>","text":"<p>mibipret module for data visualization.</p>"},{"location":"reference/reference/#mibipret.visualize.activity","title":"<code>activity</code>","text":"<p>Activity plot.</p> <p>@author: alraune</p>"},{"location":"reference/reference/#mibipret.visualize.activity.activity","title":"<code>activity(data, save_fig=False, **kwargs)</code>","text":"<p>Function creating activity plot.</p> <p>Activity plot showing scatter of total number of metabolites vs total concentration of contaminant per well with color coding of NA traffic lights: red/yellow/green corresponding to no natural attenuation going on (red), limited/unknown NA activity (yellow) or active natural attenuation (green)</p>"},{"location":"reference/reference/#mibipret.visualize.activity.activity--input","title":"Input","text":"<pre><code>data: list or pandas.DataFrame\n    quantities required in plot:\n        - total concentration of contaminants per sample\n        - total count of metabolites per sample\n        - traffic light on NA activity per sample\n    if DataFrame, it contains the three required quantities with their standard names\n    if list of arrays: the three quantities are given order above\n    if list of pandas-Series, quantities given in standard names\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string. =\n**kwargs: dict\n    dictionary with plot settings\n</code></pre>"},{"location":"reference/reference/#mibipret.visualize.activity.activity--output","title":"Output","text":"<pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibipret/visualize/activity.py</code> <pre><code>def activity(\n        data,\n        save_fig=False,\n        **kwargs,\n        ):\n    \"\"\"Function creating activity plot.\n\n    Activity plot showing scatter of total number of metabolites vs total concentration\n    of contaminant per well with color coding of NA traffic lights: red/yellow/green\n    corresponding to no natural attenuation going on (red), limited/unknown NA activity (yellow)\n    or active natural attenuation (green)\n\n    Input\n    ----------\n        data: list or pandas.DataFrame\n            quantities required in plot:\n                - total concentration of contaminants per sample\n                - total count of metabolites per sample\n                - traffic light on NA activity per sample\n            if DataFrame, it contains the three required quantities with their standard names\n            if list of arrays: the three quantities are given order above\n            if list of pandas-Series, quantities given in standard names\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string. =\n        **kwargs: dict\n            dictionary with plot settings\n\n    Output\n    -------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    ### ---------------------------------------------------------------------------\n    ### Handling of input data\n    if isinstance(data, pd.DataFrame):\n        meta_count = data[name_metabolites_variety].values\n        tot_cont = data[name_total_contaminants].values\n        well_color = data[name_na_traffic_light].values\n    elif isinstance(data, list) and len(data)&gt;=3:\n        if isinstance(data[0], pd.Series) and isinstance(data[1], pd.Series) and isinstance(data[2], pd.Series):\n            for series in data:\n                if series.name == name_metabolites_variety:\n                    meta_count = series.values\n                if series.name == name_total_contaminants:\n                    tot_cont = series.values\n                if series.name == name_na_traffic_light:\n                    well_color = series.values\n        elif isinstance(data[0], (np.ndarray, list)):\n            tot_cont = data[0]\n            meta_count = data[1]\n            well_color = data[2]\n            # print(\"MATCH\")\n        else:\n            raise ValueError(\"List elements in data must be lists, np.arrays or pd.series.\")\n        if len(tot_cont) != len(meta_count) or len(tot_cont) != len(well_color):\n            raise ValueError(\"Provided arrays/lists/series of data must have the same length.\")\n    else:\n        raise ValueError(\"Data needs to be DataFrame or list of at least three lists/np.arrays/pd.series.\")\n\n    if len(tot_cont) &lt;= 1:\n        raise ValueError(\"Too little data for activity plot. At least two values per quantity required.\")\n\n    ### ---------------------------------------------------------------------------\n    ### Creating Figure\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(tot_cont,\n               meta_count,\n               c=well_color,\n               zorder = 3,\n               s = settings['markersize'],\n               ec = settings['ec'],\n               lw = settings['lw'],\n               )\n\n    ### generate legend labels\n    if \"green\" in well_color:\n        ax.scatter([], [],\n                   label=\"available\",\n                   c=\"green\",\n                   s = settings['markersize'],\n                   ec = settings['ec'],\n                   lw = settings['lw'],\n                   )\n    if \"y\" in well_color:\n        ax.scatter([], [],\n                   label=\"limited/unknown\",\n                   c=\"y\",\n                   s = settings['markersize'],\n                   ec = settings['ec'],\n                   lw = settings['lw'],\n                   )\n    if \"red\" in well_color:\n        ax.scatter([], [],\n                   label=\"depleted\",\n                   c=\"red\",\n                   s = settings['markersize'],\n                   ec = settings['ec'],\n                   lw = settings['lw'],\n                   )\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n    ax.set_xlabel(r\"Concentration contaminants [$\\mu$g/L]\",fontsize=settings['textsize'])\n    ax.set_ylabel(\"Metabolite variety\", fontsize=settings['textsize'])\n    ax.grid()\n    ax.minorticks_on()\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=settings['textsize'])\n    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=settings['textsize'])\n    plt.legend(title = 'Electron acceptors:',loc =settings['loc'], fontsize=settings['textsize'] )\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig, ax\n</code></pre>"},{"location":"reference/reference/#mibipret.visualize.ordination_plot","title":"<code>ordination_plot</code>","text":"<p>Ordination plot.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.visualize.ordination_plot.ordination_plot","title":"<code>ordination_plot(ordination_output, plot_loadings=True, plot_scores=True, rescale_loadings_scores=False, adjust_text=True, scale_focus='loadings', axis_ranges=False, save_fig=False, **kwargs)</code>","text":"<p>Function creating ordination plot.</p> <p>Based on ordination analysis providing ordination loadings and scores.</p>"},{"location":"reference/reference/#mibipret.visualize.ordination_plot.ordination_plot--input","title":"Input","text":"<pre><code>ordination_output : Dictionary\n    contains ordination results:\n        - as numpy arrays; ordination loading and scores\n        - names of the samples and the Environmental and Species variables\n        - method : String (pca, cca, rda) The ordination method used in the analysis.\nplot_loadings : Boolean; default is True\n    flag to plot the ordination loadings\nplot_scores : Boolean; default is True\n    flag to plot the ordiantion scores\nrescale_loadings_scores : Boolean; default is False\n    flag to rescale loadings and scores to have a loading close to 1\nadjust_text : Boolean, default is True\n    flag to perform automized adjustment of text labes of loadings and scores to avoid overlap\nscale_focus : String, default is \"loadings\"\n    flag to specify if scaling focusses on either 'loadings' or 'scores' or 'none'.\naxis_ranges : Boolean or list/array of 4 values, default is False,\n    if array or list it gives fixed x and y axis dimensions [x_min, x_maxm y_min, y_max]\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string.\n**kwargs: dict\n    dictionary with plot settings (e.g. fonts, arrow specifics, etc)\n</code></pre>"},{"location":"reference/reference/#mibipret.visualize.ordination_plot.ordination_plot--output","title":"Output","text":"<pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibipret/visualize/ordination_plot.py</code> <pre><code>def ordination_plot(ordination_output,\n                    plot_loadings = True,\n                    plot_scores = True,\n                    rescale_loadings_scores = False,\n                    adjust_text = True,\n                    scale_focus = \"loadings\",\n                    axis_ranges = False,\n                    save_fig=False,\n                    **kwargs,\n                    ):\n    \"\"\"Function creating ordination plot.\n\n    Based on ordination analysis providing ordination loadings and scores.\n\n    Input\n    -----\n        ordination_output : Dictionary\n            contains ordination results:\n                - as numpy arrays; ordination loading and scores\n                - names of the samples and the Environmental and Species variables\n                - method : String (pca, cca, rda) The ordination method used in the analysis.\n        plot_loadings : Boolean; default is True\n            flag to plot the ordination loadings\n        plot_scores : Boolean; default is True\n            flag to plot the ordiantion scores\n        rescale_loadings_scores : Boolean; default is False\n            flag to rescale loadings and scores to have a loading close to 1\n        adjust_text : Boolean, default is True\n            flag to perform automized adjustment of text labes of loadings and scores to avoid overlap\n        scale_focus : String, default is \"loadings\"\n            flag to specify if scaling focusses on either 'loadings' or 'scores' or 'none'.\n        axis_ranges : Boolean or list/array of 4 values, default is False,\n            if array or list it gives fixed x and y axis dimensions [x_min, x_maxm y_min, y_max]\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string.\n        **kwargs: dict\n            dictionary with plot settings (e.g. fonts, arrow specifics, etc)\n\n    Output\n    ------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    ### ---------------------------------------------------------------------------\n    ### check on completeness of input ordination_output\n\n    if not isinstance(ordination_output,dict):\n        raise TypeError(\"Input data must be given as dictionary with standard output of ordination methods.\")\n\n    if \"loadings_independent\" not in ordination_output.keys():\n        raise KeyError(\"Input dictionary does not contain data on loadings ('loadings_independent')\")\n    else:\n        loadings_independent = ordination_output[\"loadings_independent\"]\n        names_independent = ordination_output[\"names_independent\"]\n        if len(loadings_independent) == 0:\n            loadings_independent = np.array([[],[]]).T\n\n    if \"scores\" not in ordination_output.keys():\n        raise KeyError(\"Input dictionary does not contain data on scores ('scores')\")\n    else:\n        scores = ordination_output[\"scores\"]\n\n    if \"sample_index\" not in ordination_output.keys():\n        sample_index = np.arange(scores.shape[0])\n    else:\n        sample_index = ordination_output[\"sample_index\"]\n\n    if \"loadings_dependent\" in ordination_output.keys():\n        loadings_dependent = ordination_output[\"loadings_dependent\"]\n        names_dependent = ordination_output[\"names_dependent\"]\n        if len(loadings_dependent) == 0:\n            loadings_dependent = np.array([[],[]]).T\n        loadings = np.append(loadings_independent, loadings_dependent, axis=0)\n    else:\n        loadings = loadings_independent\n\n    ### ---------------------------------------------------------------------------\n    ### Rescale ordination_output given plot specifics\n\n    # Determing the largest values in the PCA scores.\n    max_load = np.max(np.abs(loadings))\n    max_score = np.max(np.abs(scores))\n\n    if max_load &gt; 1 or rescale_loadings_scores:\n        # loadings = loadings / (max_load*1.05)\n        loadings = loadings / (max_load)\n    if max_score &gt; 1 or rescale_loadings_scores:\n        # scores = scores / (max_score*1.05)\n        scores = scores / (max_score)\n\n    if axis_ranges is not False:\n        # Takes the given axis dimensions for both ordination axes\n        x_lim_neg,x_lim_pos,y_lim_neg,y_lim_pos = axis_ranges\n    else:\n        # Adjusts axis dimensions for both ordination axes to ordination_output\n        if plot_scores and plot_loadings:\n            # When plotting both scores and loadings, scores or loadings are scaled\n            # depending on the extent of the other. Depends on the input of Scale_focus.\n            if scale_focus == \"loadings\":\n                scores = scores * np.max(np.abs(loadings))\n            elif scale_focus == \"scores\":\n                loadings = loadings *  np.max(np.abs(scores))\n            full_coords = np.append(loadings, scores, axis=0)\n        elif plot_loadings:\n            full_coords = loadings\n        else:\n            full_coords = scores\n\n        x_lim_pos = 0.11*np.ceil(np.max(full_coords[:,0])*10)\n        y_lim_pos = 0.11*np.ceil(np.max(full_coords[:,1])*10)\n        x_lim_neg = 0.11*np.floor(np.min(full_coords[:,0])*10)\n        y_lim_neg = 0.11*np.floor(np.min(full_coords[:,1])*10)\n\n    ### ---------------------------------------------------------------------------\n    ### Create Figure, finally!\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    texts = []\n\n    # Plotting the ordination scores by iterating over every coordinate\n    # in the scores array, if the Plot_scores parameter is set to true.\n    if plot_scores:\n        for i, (x, y) in enumerate(scores):\n            plt.scatter(x, y,\n                        color=settings['score_color'],\n                        marker = settings['score_marker'],\n                        s = settings['score_marker_size'],\n                        facecolor=settings['score_facecolor'],\n                        edgecolor=settings['score_edgecolor'],\n                        zorder = 7,\n                        )\n            # Plotting the name of the scores and storing it in a list for the purpose of adjusting the position later\n            tex = plt.text(x, y, sample_index[i], color='black', fontsize = settings['score_fontsize'],zorder = 9)\n            texts.append(tex)\n\n    if plot_loadings:\n        # Plots independent (=environmental) and dependent (=species) variables\n        # with different colours and text formatting.\n        for i, (x, y) in enumerate(loadings_independent):\n            plt.arrow(0, 0, x, y,\n                      color = settings['arrow_color_independent'],\n                      width = settings['arrow_width'],\n                      head_length = settings['arrow_head_length'],\n                      head_width = settings['arrow_head_width'],\n                      zorder = 10,\n                      )\n            #Plotting the name of the loading\n            tex = plt.text(x, y, names_independent[i],\n                            color='black',\n                            fontstyle = settings['fontstyle_independent'],\n                            weight = settings['weight_independent'],\n                            fontsize = settings['loading_fontsize'],\n                            zorder = 11,\n                            )\n            texts.append(tex)\n        if \"loadings_dependent\" in ordination_output.keys():\n            for i, (x, y) in enumerate(loadings_dependent):\n                plt.arrow(0, 0, x, y,\n                          color=settings['arrow_color_dependent'],\n                          width = settings['arrow_width'],\n                          head_length = settings['arrow_head_length'],\n                          head_width = settings['arrow_head_width'],\n                          zorder = 8,\n                          )\n                tex = plt.text(x, y, names_dependent[i],\n                                color='black',\n                                fontstyle = settings['fontstyle_dependent'],\n                                weight = settings['weight_dependent'],\n                                fontsize = settings['loading_fontsize'],\n                                zorder = 9,\n                                )\n                # and storing it in a list for the purpose of adjusting the position later\n                texts.append(tex)\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    # Plotting lines that indicate the origin\n    plt.plot([-1, 1], [0, 0], color='grey', linewidth=0.75, linestyle='--')\n    plt.plot([0, 0], [-1, 1], color='grey', linewidth=0.75, linestyle='--')\n\n    # Setting the x and y axis limits with the previously determined values\n    plt.xlim(x_lim_neg, x_lim_pos)\n    plt.ylim(y_lim_neg, y_lim_pos)\n    plt.tick_params(axis=\"both\",which=\"major\",labelsize=settings['label_fontsize'])\n\n    if ordination_output[\"method\"]=='pca':\n        percent_explained = ordination_output[\"percent_explained\"]\n        plt.xlabel('PC1 ({:.1f}%)'.format(percent_explained[0]), fontsize = settings['label_fontsize'])\n        plt.ylabel('PC2 ({:.1f}%)'.format(percent_explained[1]), fontsize = settings['label_fontsize'])\n    else:\n        plt.xlabel('ordination axis 1', fontsize = settings['label_fontsize'])\n        plt.ylabel('ordination axis 2', fontsize = settings['label_fontsize'])\n\n    if adjust_text:\n        try:\n            from adjustText import adjust_text\n            adjust_text(texts)\n        except ImportError:\n            print(\"WARNING: packages 'adjustText' not installed.\")\n            print(\" For making text adjustment, install package 'adjustText'.\")\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n\n    plt.tight_layout()\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Figure saved to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig, ax\n</code></pre>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots","title":"<code>stable_isotope_plots</code>","text":"<p>Linear regression plots for stable isotope analysis in mibipret.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots.Keeling_plot","title":"<code>Keeling_plot(concentration, delta, coefficients, relative_abundance=None, save_fig=False, **kwargs)</code>","text":"<p>Creating a Keeling plot.</p> <p>A Keeling plot is an approach to identify the isotopic composition of a contaminating source from measured concentrations and isotopic composition (delta) of a target species in the mix of the source and a pool. It is based on the linear relationship of the concentration and the delta-value which are measured over time or across a spatial interval.</p> <p>The plot shows the inverse concentration data against the delta-values along the linear regression line. For gaining the regression coefficients perform a linear fitting or run</p> <pre><code>Keeling_regression() [in the module analysis]\n</code></pre> <p>The parameter of interest, the delta (or relative_abundance, respectively) of the source quantity is the intercept of linear fit with the y-axis, or in other words, the absolute value of the linear fit function.</p>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots.Keeling_plot--input","title":"Input","text":"<pre><code>c_mix : np.array, pd.dataframe\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta_mix : np.array, pd.dataframe (same length as c_mix)\n    relative isotope ratio (delta-value) of target substance\nrelative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n    if not None it replaces delta_mix in the inverse estimation and plotting\n    relative abundance of target substance\ncoefficients : tuple of lenght 2\n    containing coefficients of the linear fit\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string. =\n**kwargs: dict\n    dictionary with plot settings\n</code></pre> <pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibipret/visualize/stable_isotope_plots.py</code> <pre><code>def Keeling_plot(concentration,\n                 delta,\n                 coefficients,\n                 relative_abundance = None,\n                 save_fig = False,\n                 **kwargs,\n                 ):\n    \"\"\"Creating a Keeling plot.\n\n    A Keeling plot is an approach to identify the isotopic composition of a\n    contaminating source from measured concentrations and isotopic composition\n    (delta) of a target species in the mix of the source and a pool. It is based\n    on the linear relationship of the concentration and the delta-value\n    which are measured over time or across a spatial interval.\n\n    The plot shows the inverse concentration data against the delta-values\n    along the linear regression line. For gaining the regression coefficients\n    perform a linear fitting or run\n\n        Keeling_regression() [in the module analysis]\n\n    The parameter of interest, the delta (or relative_abundance, respectively)\n    of the source quantity is the intercept of linear fit with the y-axis,\n    or in other words, the absolute value of the linear fit function.\n\n    Input\n    -----\n        c_mix : np.array, pd.dataframe\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta_mix : np.array, pd.dataframe (same length as c_mix)\n            relative isotope ratio (delta-value) of target substance\n        relative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n            if not None it replaces delta_mix in the inverse estimation and plotting\n            relative abundance of target substance\n        coefficients : tuple of lenght 2\n            containing coefficients of the linear fit\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string. =\n        **kwargs: dict\n            dictionary with plot settings\n\n    Returns:\n    --------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    if relative_abundance is not None:\n        y = relative_abundance\n        text = 'x'\n    else:\n        y = delta\n        text = r\"\\delta\"\n\n    x = 1/concentration\n\n    ### ---------------------------------------------------------------------------\n    ### create plot\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(x,y, marker=settings['marker'], zorder = 3,label = 'data')\n\n    ### ---------------------------------------------------------------------------\n    ### plot linear regression trend line\n\n    polynomial = np.poly1d(coefficients)\n    trendline_x = np.linspace(min(0,np.min(x)),np.max(x), 100)\n    trendline_y = polynomial(trendline_x)\n\n    ax.plot(trendline_x, trendline_y, color= settings['fit_color'], label='linear fit')\n    ax.text(0.5, 0.1,\n            r\"${}_{{source}} = {:.3f}$\".format(text,coefficients[1]),\n             bbox=dict(boxstyle=\"round\", facecolor='w'),#,alpha=0.5)\n             transform=ax.transAxes,\n             fontsize=settings['fontsize'])\n    ax.scatter(0,coefficients[1],\n               c = settings['intercept_color'],\n               zorder = 3,\n               label = r'intercept: ${}_{{source}}$'.format(text),\n               )\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    ax.set_xlabel('Inverse concentration $1/c$',fontsize=settings['fontsize'])\n    ax.set_ylabel('${}$'.format(text),fontsize=settings['fontsize'])\n    ax.grid(True,zorder = 0)\n    ax.set_xlim([0-x[-1]*0.05, x[-1]*1.05])\n    ax.legend(loc =settings['loc'], fontsize=settings['fontsize'])\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig,ax\n</code></pre>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots.Lambda_plot","title":"<code>Lambda_plot(delta_C, delta_H, coefficients, save_fig=False, **kwargs)</code>","text":"<p>Creating a Lambda plot.</p> <p>A Lambda plot shows the \u03b413C versus \u03b42H signatures of a chemical compound. Relative changes in the carbon and hydrogen isotope ratios can indicate the occurrence of specific enzymatic degradation reactions. The relative changes are indicated by the lambda-H/C value which is the slope of the linear regression of hydrogen versus carbon isotope signatures. For gaining the regression coefficients perform a linear fitting or run</p> <pre><code> Lambda_regression() [in the module analysis]\n</code></pre> Lambda-values linking to specific enzymatic reactions <p>To be added!</p> <p>Details provided in Vogt et al. [2016, 2020].</p> References <p>C. Vogt, C. Dorer, F. Musat, and H. H. Richnow. Multi-element isotope fractionation concepts to characterize the biodegradation of hydrocarbons - from enzymes to the environment. Current Opinion in Biotechnology, 41:90\u201398, 2016. C. Vogt, F. Musat, and H.-H. Richnow. Compound-Specific Isotope Analysis for Studying the Biological Degradation of Hydrocarbons. In Anaerobic Utilization of Hydrocarbons, Oils, and Lipids, pages 285-321. Springer Nature Switzerland, 2020.</p> <p>A. Fischer, I. Herklotz, S. Herrmann, M. Thullner, S. A. Weelink, A. J. Stams, M. Schl \u0308omann, H.-H. Richnow, and C. Vogt. Combined Carbon and Hydrogen Isotope Fractionation Investigations for Elucidating Benzene Biodegradation Pathways. Environmental Science and Technology, 42:4356\u20134363, 2008.</p> <p>S. Kuemmel, F.-A. Herbst, A. Bahr, M. Arcia Duarte, D. H. Pieper, N. Jehmlich, J. Seifert, M. Von Bergen, P. Bombach, H. H. Richnow, and C. Vogt. Anaerobic naphthalene degradation by sulfate-reducing Desulfobacteraceae from various anoxic aquifers. FEMS Microbiology Ecology, 91(3), 2015.</p>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots.Lambda_plot--input","title":"Input","text":"<pre><code>delta_C : np.array, pd.series\n    relative isotope ratio (delta-value) of carbon of target molecule\ndelta_H : np.array, pd.series (same length as delta_C)\n    relative isotope ratio (delta-value) of hydrogen of target molecule\ncoefficients : tuple of lenght 2\n    containing coefficients of the linear fit\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string.\n**kwargs: dict\n    dictionary with plot settings\n</code></pre> <pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibipret/visualize/stable_isotope_plots.py</code> <pre><code>def Lambda_plot(delta_C,\n                delta_H,\n                coefficients,\n                save_fig = False,\n                **kwargs,\n                ):\n    \"\"\"Creating a Lambda plot.\n\n    A Lambda plot shows the \u03b413C versus \u03b42H signatures of a chemical compound.\n    Relative changes in the carbon and hydrogen isotope ratios can indicate the\n    occurrence of specific enzymatic degradation reactions. The relative changes\n    are indicated by the lambda-H/C value which is the slope of the linear\n    regression of hydrogen versus carbon isotope signatures. For gaining the\n    regression coefficients perform a linear fitting or run\n\n         Lambda_regression() [in the module analysis]\n\n    Lambda-values linking to specific enzymatic reactions:\n        To be added!\n\n    Details provided in Vogt et al. [2016, 2020].\n\n    References:\n        C. Vogt, C. Dorer, F. Musat, and H. H. Richnow. Multi-element isotope\n        fractionation concepts to characterize the biodegradation of hydrocarbons\n        - from enzymes to the environment. Current Opinion in Biotechnology,\n        41:90\u201398, 2016.\n        C. Vogt, F. Musat, and H.-H. Richnow. Compound-Specific Isotope Analysis\n        for Studying the Biological Degradation of Hydrocarbons. In Anaerobic\n        Utilization of Hydrocarbons, Oils, and Lipids, pages 285-321.\n        Springer Nature Switzerland, 2020.\n\n        A. Fischer, I. Herklotz, S. Herrmann, M. Thullner, S. A. Weelink,\n        A. J. Stams, M. Schl \u0308omann, H.-H. Richnow, and C. Vogt. Combined Carbon\n        and Hydrogen Isotope Fractionation Investigations for Elucidating\n        Benzene Biodegradation Pathways. Environmental Science and Technology,\n        42:4356\u20134363, 2008.\n\n        S. Kuemmel, F.-A. Herbst, A. Bahr, M. Arcia Duarte, D. H. Pieper,\n        N. Jehmlich, J. Seifert, M. Von Bergen, P. Bombach, H. H. Richnow,\n        and C. Vogt. Anaerobic naphthalene degradation by sulfate-reducing\n        Desulfobacteraceae from various anoxic aquifers.\n        FEMS Microbiology Ecology, 91(3), 2015.\n\n    Input\n    -----\n        delta_C : np.array, pd.series\n            relative isotope ratio (delta-value) of carbon of target molecule\n        delta_H : np.array, pd.series (same length as delta_C)\n            relative isotope ratio (delta-value) of hydrogen of target molecule\n        coefficients : tuple of lenght 2\n            containing coefficients of the linear fit\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string.\n        **kwargs: dict\n            dictionary with plot settings\n\n    Returns:\n    --------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(delta_C, delta_H, marker=settings['marker'],zorder = 3,label= 'data')\n\n    ### ---------------------------------------------------------------------------\n    ### plot linear regression trend line\n\n    polynomial = np.poly1d(coefficients)\n    trendline_x = np.linspace(np.min(delta_C), np.max(delta_C), 100)\n    trendline_y = polynomial(trendline_x)\n    ax.plot(trendline_x, trendline_y, color= settings['fit_color'], label='linear fit')\n    ax.text(0.4, 0.1,\n             r\"$\\Lambda = {:.2f}$\".format(coefficients[0]),\n             bbox=dict(boxstyle=\"round\", facecolor='w'),#,alpha=0.5),\n             transform=ax.transAxes,\n             fontsize=settings['fontsize'])\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    ax.grid(True,zorder = 0)\n    ax.set_xlabel(r'$\\delta^{{13}}$C')\n    ax.set_ylabel(r'$\\delta^2$H')\n    ax.legend(loc =settings['loc'], fontsize=settings['fontsize'])\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig,ax\n</code></pre>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots.Rayleigh_fractionation_plot","title":"<code>Rayleigh_fractionation_plot(concentration, delta, coefficients, save_fig=False, **kwargs)</code>","text":"<p>Creating a Rayleigh fractionation plot.</p> <p>Rayleigh fractionation is a common application to characterize the removal of a substance from a finite pool using stable isotopes. It is based on the change in the isotopic composition of the pool due to different kinetics of the change in lighter and heavier isotopes.</p> <p>We follow the most simple approach assuming that the substance removal follows first-order kinetics, where the rate coefficients for the lighter and heavier isotopes of the substance differ due to kinetic isotope fractionation effects. The isotopic composition of the remaining substance in the pool will change over time, leading to the so-called Rayleigh fractionation.</p> <p>The plot shows the log-transformed concentration data against the delta-values along the linear regression line. For gaining the regression coefficients perform a linear fitting or run</p> <pre><code>Rayleigh_fractionation() [in the module analysis]\n</code></pre> <p>The parameter of interest, the kinetic fractionation factor (epsilon or alpha -1) of the removal process is the slope of the the linear trend line.</p>"},{"location":"reference/reference/#mibipret.visualize.stable_isotope_plots.Rayleigh_fractionation_plot--input","title":"Input","text":"<pre><code>concentration : np.array, pd.series\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta : np.array, pd.series (same length as concentration)\n    relative isotope ratio (delta-value) of target substance\ncoefficients : tuple of lenght 2\n    containing coefficients of the linear fit\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string. =\n**kwargs: dict\n    dictionary with plot settings\n</code></pre> <pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibipret/visualize/stable_isotope_plots.py</code> <pre><code>def Rayleigh_fractionation_plot(concentration,\n                                delta,\n                                coefficients,\n                                save_fig = False,\n                                **kwargs,\n                                ):\n    \"\"\"Creating a Rayleigh fractionation plot.\n\n    Rayleigh fractionation is a common application to characterize the removal\n    of a substance from a finite pool using stable isotopes. It is based on the\n    change in the isotopic composition of the pool due to different kinetics of\n    the change in lighter and heavier isotopes.\n\n    We follow the most simple approach assuming that the substance removal follows\n    first-order kinetics, where the rate coefficients for the lighter and heavier\n    isotopes of the substance differ due to kinetic isotope fractionation effects.\n    The isotopic composition of the remaining substance in the pool will change\n    over time, leading to the so-called Rayleigh fractionation.\n\n    The plot shows the log-transformed concentration data against the delta-values\n    along the linear regression line. For gaining the regression coefficients\n    perform a linear fitting or run\n\n        Rayleigh_fractionation() [in the module analysis]\n\n    The parameter of interest, the kinetic fractionation factor (epsilon or alpha -1)\n    of the removal process is the slope of the the linear trend line.\n\n    Input\n    -----\n        concentration : np.array, pd.series\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta : np.array, pd.series (same length as concentration)\n            relative isotope ratio (delta-value) of target substance\n        coefficients : tuple of lenght 2\n            containing coefficients of the linear fit\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string. =\n        **kwargs: dict\n            dictionary with plot settings\n\n    Returns:\n    --------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    x = np.log(concentration)\n    ### ---------------------------------------------------------------------------\n    ### create plot\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(x,delta, marker=settings['marker'], zorder = 3,label = 'data')\n\n    ### ---------------------------------------------------------------------------\n    ### plot linear regression trend line\n\n    polynomial = np.poly1d(coefficients)\n    trendline_x = np.linspace(np.min(x), np.max(x), 100)\n    trendline_y = polynomial(trendline_x)\n    ax.plot(trendline_x, trendline_y, color= settings['fit_color'], label='linear fit')\n    ax.text(0.1, 0.1,\n             r\"$\\epsilon = 1-\\alpha = {:.3f}$\".format(coefficients[0]),\n             bbox=dict(boxstyle=\"round\", facecolor='w'),#,alpha=0.5),\n             transform=ax.transAxes,\n             fontsize=settings['fontsize'])\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    ax.set_xlabel(r'log-concentration $\\ln c$',fontsize=settings['fontsize'])\n    ax.set_ylabel(r'$\\delta$',fontsize=settings['fontsize'])\n    ax.grid(True,zorder = 0)\n    ax.legend(loc =settings['loc'], fontsize=settings['fontsize'])\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig,ax\n</code></pre>"}]}